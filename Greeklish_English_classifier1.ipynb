{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Importing Libraries"
      ],
      "metadata": {
        "id": "wdK15MUPq7Le"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tc1LvZ-0eNUw",
        "outputId": "561bb5c2-1b90-4b62-ba61-dc06129b3133"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (4.13.3)\n",
            "Requirement already satisfied: scrapy in /usr/local/lib/python3.11/dist-packages (2.12.0)\n",
            "Requirement already satisfied: selenium in /usr/local/lib/python3.11/dist-packages (4.30.0)\n",
            "Requirement already satisfied: newspaper3k in /usr/local/lib/python3.11/dist-packages (0.2.8)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.1.31)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (2.6)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (4.13.0)\n",
            "Requirement already satisfied: Twisted>=21.7.0 in /usr/local/lib/python3.11/dist-packages (from scrapy) (24.11.0)\n",
            "Requirement already satisfied: cryptography>=37.0.0 in /usr/local/lib/python3.11/dist-packages (from scrapy) (43.0.3)\n",
            "Requirement already satisfied: cssselect>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from scrapy) (1.3.0)\n",
            "Requirement already satisfied: itemloaders>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from scrapy) (1.3.2)\n",
            "Requirement already satisfied: parsel>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from scrapy) (1.10.0)\n",
            "Requirement already satisfied: pyOpenSSL>=22.0.0 in /usr/local/lib/python3.11/dist-packages (from scrapy) (24.2.1)\n",
            "Requirement already satisfied: queuelib>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from scrapy) (1.8.0)\n",
            "Requirement already satisfied: service-identity>=18.1.0 in /usr/local/lib/python3.11/dist-packages (from scrapy) (24.2.0)\n",
            "Requirement already satisfied: w3lib>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from scrapy) (2.3.1)\n",
            "Requirement already satisfied: zope.interface>=5.1.0 in /usr/local/lib/python3.11/dist-packages (from scrapy) (7.2)\n",
            "Requirement already satisfied: protego>=0.1.15 in /usr/local/lib/python3.11/dist-packages (from scrapy) (0.4.0)\n",
            "Requirement already satisfied: itemadapter>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from scrapy) (0.11.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from scrapy) (24.2)\n",
            "Requirement already satisfied: tldextract in /usr/local/lib/python3.11/dist-packages (from scrapy) (5.1.3)\n",
            "Requirement already satisfied: lxml>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from scrapy) (5.3.1)\n",
            "Requirement already satisfied: defusedxml>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from scrapy) (0.7.1)\n",
            "Requirement already satisfied: PyDispatcher>=2.0.5 in /usr/local/lib/python3.11/dist-packages (from scrapy) (2.0.7)\n",
            "Requirement already satisfied: trio~=0.17 in /usr/local/lib/python3.11/dist-packages (from selenium) (0.29.0)\n",
            "Requirement already satisfied: trio-websocket~=0.9 in /usr/local/lib/python3.11/dist-packages (from selenium) (0.12.2)\n",
            "Requirement already satisfied: websocket-client~=1.8 in /usr/local/lib/python3.11/dist-packages (from selenium) (1.8.0)\n",
            "Requirement already satisfied: Pillow>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from newspaper3k) (11.1.0)\n",
            "Requirement already satisfied: PyYAML>=3.11 in /usr/local/lib/python3.11/dist-packages (from newspaper3k) (6.0.2)\n",
            "Requirement already satisfied: nltk>=3.2.1 in /usr/local/lib/python3.11/dist-packages (from newspaper3k) (3.9.1)\n",
            "Requirement already satisfied: feedparser>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from newspaper3k) (6.0.11)\n",
            "Requirement already satisfied: feedfinder2>=0.0.4 in /usr/local/lib/python3.11/dist-packages (from newspaper3k) (0.0.4)\n",
            "Requirement already satisfied: jieba3k>=0.35.1 in /usr/local/lib/python3.11/dist-packages (from newspaper3k) (0.35.1)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from newspaper3k) (2.8.2)\n",
            "Requirement already satisfied: tinysegmenter==0.3 in /usr/local/lib/python3.11/dist-packages (from newspaper3k) (0.3)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=37.0.0->scrapy) (1.17.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from feedfinder2>=0.0.4->newspaper3k) (1.17.0)\n",
            "Requirement already satisfied: sgmllib3k in /usr/local/lib/python3.11/dist-packages (from feedparser>=5.2.1->newspaper3k) (1.0.0)\n",
            "Requirement already satisfied: jmespath>=0.9.5 in /usr/local/lib/python3.11/dist-packages (from itemloaders>=1.0.1->scrapy) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk>=3.2.1->newspaper3k) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk>=3.2.1->newspaper3k) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk>=3.2.1->newspaper3k) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk>=3.2.1->newspaper3k) (4.67.1)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.11/dist-packages (from service-identity>=18.1.0->scrapy) (25.3.0)\n",
            "Requirement already satisfied: pyasn1 in /usr/local/lib/python3.11/dist-packages (from service-identity>=18.1.0->scrapy) (0.6.1)\n",
            "Requirement already satisfied: pyasn1-modules in /usr/local/lib/python3.11/dist-packages (from service-identity>=18.1.0->scrapy) (0.4.2)\n",
            "Requirement already satisfied: requests-file>=1.4 in /usr/local/lib/python3.11/dist-packages (from tldextract->scrapy) (2.1.0)\n",
            "Requirement already satisfied: filelock>=3.0.8 in /usr/local/lib/python3.11/dist-packages (from tldextract->scrapy) (3.18.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.11/dist-packages (from trio~=0.17->selenium) (2.4.0)\n",
            "Requirement already satisfied: outcome in /usr/local/lib/python3.11/dist-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
            "Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from trio~=0.17->selenium) (1.3.1)\n",
            "Requirement already satisfied: wsproto>=0.14 in /usr/local/lib/python3.11/dist-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
            "Requirement already satisfied: automat>=24.8.0 in /usr/local/lib/python3.11/dist-packages (from Twisted>=21.7.0->scrapy) (24.8.1)\n",
            "Requirement already satisfied: constantly>=15.1 in /usr/local/lib/python3.11/dist-packages (from Twisted>=21.7.0->scrapy) (23.10.4)\n",
            "Requirement already satisfied: hyperlink>=17.1.1 in /usr/local/lib/python3.11/dist-packages (from Twisted>=21.7.0->scrapy) (21.0.0)\n",
            "Requirement already satisfied: incremental>=24.7.0 in /usr/local/lib/python3.11/dist-packages (from Twisted>=21.7.0->scrapy) (24.7.2)\n",
            "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from zope.interface>=5.1.0->scrapy) (75.2.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=37.0.0->scrapy) (2.22)\n",
            "Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
          ]
        }
      ],
      "source": [
        "pip install requests beautifulsoup4 scrapy selenium newspaper3k\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Data** **Collection**"
      ],
      "metadata": {
        "id": "KO0pwKQyMHLp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extracting Greek data"
      ],
      "metadata": {
        "id": "nOKMCSaDrY1s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Resource 1"
      ],
      "metadata": {
        "id": "Jkl8xdM6rpkj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# List of Greeklish forum URLs\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# List of Greeklish forum URLs\n",
        "urls = [\n",
        "    \"https://www.textkit.com/greek-latin-forum/viewtopic.php?t=64754\",\n",
        "    \"https://www.prestashop.com/forums/topic/1046273-xml-%CF%80%CF%81%CE%BF%CE%B9%CE%BF%CE%BD%CF%84%CE%B1/\",\n",
        "    \"https://athinapoli.gr/category/city/\",\n",
        "    \"https://greek-articles.blogspot.com/?utm_source=chatgpt.com\",\n",
        "    \"\"\n",
        "]\n",
        "\n",
        "# Open file to save data\n",
        "with open(\"greeklish_data.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    for url in urls:\n",
        "        print(f\"Scraping: {url}\")\n",
        "        try:\n",
        "            # Get webpage content\n",
        "            response = requests.get(url, timeout=10)\n",
        "            response.raise_for_status()  # Raise error for bad response\n",
        "\n",
        "            # Parse content\n",
        "            soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "\n",
        "            # Extract text from paragraphs\n",
        "            texts = [p.text.strip() for p in soup.find_all(\"p\") if p.text.strip()]\n",
        "\n",
        "            # Save extracted text\n",
        "            for text in texts:\n",
        "                f.write(text + \"\\n\")\n",
        "\n",
        "            print(f\"✅ Data saved from {url}\")\n",
        "\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            print(f\"❌ Failed to scrape {url}: {e}\")\n",
        "\n",
        "print(\"✅ Greeklish data collection completed!\")\n",
        "\n",
        "# Open file to save data\n",
        "with open(\"greeklish_data.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    for url in urls:\n",
        "        print(f\"Scraping: {url}\")\n",
        "        try:\n",
        "            # Get webpage content\n",
        "            response = requests.get(url, timeout=10)\n",
        "            response.raise_for_status()  # Raise error for bad response\n",
        "\n",
        "            # Parse content\n",
        "            soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "\n",
        "            # Extract text from paragraphs\n",
        "            texts = [p.text.strip() for p in soup.find_all(\"p\") if p.text.strip()]\n",
        "\n",
        "            # Save extracted text\n",
        "            for text in texts:\n",
        "                f.write(text + \"\\n\")\n",
        "\n",
        "            print(f\"✅ Data saved from {url}\")\n",
        "\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            print(f\"❌ Failed to scrape {url}: {e}\")\n",
        "\n",
        "print(\"✅ Greeklish data collection completed!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qm6jOSUhqa0F",
        "outputId": "66851388-b48e-46c8-fc94-d4f719cfbe1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scraping: https://www.textkit.com/greek-latin-forum/viewtopic.php?t=64754\n",
            "✅ Data saved from https://www.textkit.com/greek-latin-forum/viewtopic.php?t=64754\n",
            "Scraping: https://www.prestashop.com/forums/topic/1046273-xml-%CF%80%CF%81%CE%BF%CE%B9%CE%BF%CE%BD%CF%84%CE%B1/\n",
            "✅ Data saved from https://www.prestashop.com/forums/topic/1046273-xml-%CF%80%CF%81%CE%BF%CE%B9%CE%BF%CE%BD%CF%84%CE%B1/\n",
            "Scraping: https://athinapoli.gr/category/city/\n",
            "✅ Data saved from https://athinapoli.gr/category/city/\n",
            "Scraping: https://greek-articles.blogspot.com/?utm_source=chatgpt.com\n",
            "✅ Data saved from https://greek-articles.blogspot.com/?utm_source=chatgpt.com\n",
            "Scraping: \n",
            "❌ Failed to scrape : Invalid URL '': No scheme supplied. Perhaps you meant https://?\n",
            "✅ Greeklish data collection completed!\n",
            "Scraping: https://www.textkit.com/greek-latin-forum/viewtopic.php?t=64754\n",
            "✅ Data saved from https://www.textkit.com/greek-latin-forum/viewtopic.php?t=64754\n",
            "Scraping: https://www.prestashop.com/forums/topic/1046273-xml-%CF%80%CF%81%CE%BF%CE%B9%CE%BF%CE%BD%CF%84%CE%B1/\n",
            "✅ Data saved from https://www.prestashop.com/forums/topic/1046273-xml-%CF%80%CF%81%CE%BF%CE%B9%CE%BF%CE%BD%CF%84%CE%B1/\n",
            "Scraping: https://athinapoli.gr/category/city/\n",
            "✅ Data saved from https://athinapoli.gr/category/city/\n",
            "Scraping: https://greek-articles.blogspot.com/?utm_source=chatgpt.com\n",
            "✅ Data saved from https://greek-articles.blogspot.com/?utm_source=chatgpt.com\n",
            "Scraping: \n",
            "❌ Failed to scrape : Invalid URL '': No scheme supplied. Perhaps you meant https://?\n",
            "✅ Greeklish data collection completed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Resource 2"
      ],
      "metadata": {
        "id": "zpVnHmJtrwmk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# List of Greeklish forum URLs\n",
        "urls = [\n",
        "    \"https://www.greek-chat.gr/oroi-xrisis.html\",\n",
        "    \"https://www.textkit.com/greek-latin-forum/viewtopic.php?t=64754\",\n",
        "    \"https://www.textkit.com/greeklish-thread\"  # Add more URLs\n",
        "]\n",
        "\n",
        "# Open file to save data\n",
        "with open(\"greeklish_data1.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    for url in urls:\n",
        "        print(f\"🔍 Scraping: {url}\")\n",
        "        try:\n",
        "            # Get webpage content\n",
        "            response = requests.get(url, timeout=10)\n",
        "            response.raise_for_status()  # Raise error for bad response\n",
        "\n",
        "            # Parse content\n",
        "            soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "\n",
        "            # Extract text from paragraphs\n",
        "            texts = [p.text.strip() for p in soup.find_all(\"p\") if p.text.strip()]\n",
        "\n",
        "            # Save extracted text\n",
        "            for text in texts:\n",
        "                f.write(text + \"\\n\")\n",
        "\n",
        "            print(f\"✅ Data saved from {url}\")\n",
        "\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            print(f\"❌ Failed to scrape {url}: {e}\")\n",
        "\n",
        "print(\"✅ Greeklish data collection completed!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7qd77GtnrQWc",
        "outputId": "608d7c38-5563-4910-f37e-470a52014229"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Scraping: https://www.greek-chat.gr/oroi-xrisis.html\n",
            "✅ Data saved from https://www.greek-chat.gr/oroi-xrisis.html\n",
            "🔍 Scraping: https://www.textkit.com/greek-latin-forum/viewtopic.php?t=64754\n",
            "✅ Data saved from https://www.textkit.com/greek-latin-forum/viewtopic.php?t=64754\n",
            "🔍 Scraping: https://www.textkit.com/greeklish-thread\n",
            "❌ Failed to scrape https://www.textkit.com/greeklish-thread: 404 Client Error: Not Found for url: https://www.textkit.com/greeklish-thread\n",
            "✅ Greeklish data collection completed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Resource 3"
      ],
      "metadata": {
        "id": "BgkUQdbMKpEb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install praw\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SJK-bIT8uZ8e",
        "outputId": "28dcf889-62a7-483c-87cc-38511a2a8a38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: praw in /usr/local/lib/python3.11/dist-packages (7.8.1)\n",
            "Requirement already satisfied: prawcore<3,>=2.4 in /usr/local/lib/python3.11/dist-packages (from praw) (2.4.0)\n",
            "Requirement already satisfied: update_checker>=0.18 in /usr/local/lib/python3.11/dist-packages (from praw) (0.18.0)\n",
            "Requirement already satisfied: websocket-client>=0.54.0 in /usr/local/lib/python3.11/dist-packages (from praw) (1.8.0)\n",
            "Requirement already satisfied: requests<3.0,>=2.6.0 in /usr/local/lib/python3.11/dist-packages (from prawcore<3,>=2.4->praw) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.4->praw) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.4->praw) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.4->praw) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.4->praw) (2025.1.31)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import praw\n",
        "\n",
        "# Reddit API Credentials (Replace with your details)\n",
        "reddit = praw.Reddit(\n",
        "\n",
        "    client_id=\"clSKYhPjYEzMHrPEld4x3A\",\n",
        "    client_secret=\"8VQcbhXURahSmpQxl4u1S3ECiODX5A\",\n",
        "    user_agent=\"GreeklishScraper\",\n",
        "\n",
        "    username=\"Ok-Highlight-8025\",  # Needed for personal feed\n",
        "    password=\"Comsats523091\"   # Needed for personal feed\n",
        ")\n",
        "\n",
        "# Fetch posts from your own Reddit feed\n",
        "posts = []\n",
        "for post in reddit.front.hot(limit=10):  # Fetch top 10 posts\n",
        "    posts.append(post.title)\n",
        "    posts.append(post.selftext)\n",
        "\n",
        "    # Fetch top 10 comments\n",
        "    post.comments.replace_more(limit=0)\n",
        "    for comment in post.comments[:10]:\n",
        "        posts.append(comment.body)\n",
        "\n",
        "# Save data to a text file\n",
        "with open(\"my_reddit_feed.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    for post in posts:\n",
        "        f.write(post + \"\\n\\n\")\n",
        "\n",
        "print(\"✅ Your Reddit feed data has been saved successfully!\")\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZgEBA8UK8ALe",
        "outputId": "edfd9d7c-8308-4523-dfd0-1687b5283c0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Your Reddit feed data has been saved successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extracting English data"
      ],
      "metadata": {
        "id": "x3VSbDwJBMit"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Resource 1\n"
      ],
      "metadata": {
        "id": "AzPr29VJBRad"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade lxml_html_clean newspaper3k\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jeBkHvcQCn6D",
        "outputId": "e156672c-ca44-40c7-e326-2b0c09d51d49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting lxml_html_clean\n",
            "  Downloading lxml_html_clean-0.4.1-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: newspaper3k in /usr/local/lib/python3.11/dist-packages (0.2.8)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from lxml_html_clean) (5.3.1)\n",
            "Requirement already satisfied: beautifulsoup4>=4.4.1 in /usr/local/lib/python3.11/dist-packages (from newspaper3k) (4.13.3)\n",
            "Requirement already satisfied: Pillow>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from newspaper3k) (11.1.0)\n",
            "Requirement already satisfied: PyYAML>=3.11 in /usr/local/lib/python3.11/dist-packages (from newspaper3k) (6.0.2)\n",
            "Requirement already satisfied: cssselect>=0.9.2 in /usr/local/lib/python3.11/dist-packages (from newspaper3k) (1.3.0)\n",
            "Requirement already satisfied: nltk>=3.2.1 in /usr/local/lib/python3.11/dist-packages (from newspaper3k) (3.9.1)\n",
            "Requirement already satisfied: requests>=2.10.0 in /usr/local/lib/python3.11/dist-packages (from newspaper3k) (2.32.3)\n",
            "Requirement already satisfied: feedparser>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from newspaper3k) (6.0.11)\n",
            "Requirement already satisfied: tldextract>=2.0.1 in /usr/local/lib/python3.11/dist-packages (from newspaper3k) (5.1.3)\n",
            "Requirement already satisfied: feedfinder2>=0.0.4 in /usr/local/lib/python3.11/dist-packages (from newspaper3k) (0.0.4)\n",
            "Requirement already satisfied: jieba3k>=0.35.1 in /usr/local/lib/python3.11/dist-packages (from newspaper3k) (0.35.1)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from newspaper3k) (2.8.2)\n",
            "Requirement already satisfied: tinysegmenter==0.3 in /usr/local/lib/python3.11/dist-packages (from newspaper3k) (0.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4>=4.4.1->newspaper3k) (2.6)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4>=4.4.1->newspaper3k) (4.13.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from feedfinder2>=0.0.4->newspaper3k) (1.17.0)\n",
            "Requirement already satisfied: sgmllib3k in /usr/local/lib/python3.11/dist-packages (from feedparser>=5.2.1->newspaper3k) (1.0.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk>=3.2.1->newspaper3k) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk>=3.2.1->newspaper3k) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk>=3.2.1->newspaper3k) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk>=3.2.1->newspaper3k) (4.67.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.10.0->newspaper3k) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.10.0->newspaper3k) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.10.0->newspaper3k) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.10.0->newspaper3k) (2025.1.31)\n",
            "Requirement already satisfied: requests-file>=1.4 in /usr/local/lib/python3.11/dist-packages (from tldextract>=2.0.1->newspaper3k) (2.1.0)\n",
            "Requirement already satisfied: filelock>=3.0.8 in /usr/local/lib/python3.11/dist-packages (from tldextract>=2.0.1->newspaper3k) (3.18.0)\n",
            "Downloading lxml_html_clean-0.4.1-py3-none-any.whl (14 kB)\n",
            "Installing collected packages: lxml_html_clean\n",
            "Successfully installed lxml_html_clean-0.4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from newspaper import Article\n",
        "\n",
        "# List of news URLs (Add more as needed)\n",
        "news_urls = [\n",
        "    \"https://www.bbc.com/news/articles/c807lm2003zo\",\n",
        "    \"https://edition.cnn.com/2025/03/31/middleeast/aid-workers-found-gaza-mass-grave-intl-hnk/index.html\",\n",
        "    \"https://www.theguardian.com/world/2025/apr/03/canada-trump-tariffs-exemption\",\n",
        "    \"\",\n",
        "    \"\"\n",
        "]\n",
        "\n",
        "english_sentences = []\n",
        "\n",
        "for url in news_urls:\n",
        "    try:\n",
        "        article = Article(url)\n",
        "        article.download()\n",
        "        article.parse()\n",
        "\n",
        "        if article.text.strip():  # Ensure there's text\n",
        "            english_sentences.append(article.text.strip())\n",
        "            print(f\"✅ Extracted: {url}\")\n",
        "        else:\n",
        "            print(f\"⚠️ No text found: {url}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error processing {url}: {e}\")\n",
        "\n",
        "# Save extracted English data\n",
        "with open(\"english_data.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(\"\\n\\n\".join(english_sentences))\n",
        "\n",
        "print(\"✅ English news data saved successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_2mCEo4-BtoE",
        "outputId": "639c3842-6b54-4166-ac39-54e75e59d487"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Extracted: https://www.bbc.com/news/articles/c807lm2003zo\n",
            "✅ Extracted: https://edition.cnn.com/2025/03/31/middleeast/aid-workers-found-gaza-mass-grave-intl-hnk/index.html\n",
            "✅ Extracted: https://www.theguardian.com/world/2025/apr/03/canada-trump-tariffs-exemption\n",
            "❌ Error processing : Article `download()` failed with No connection adapters were found for '://' on URL ://\n",
            "❌ Error processing : Article `download()` failed with No connection adapters were found for '://' on URL ://\n",
            "✅ English news data saved successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 📝 Greeklish vs. English Dataset Preparation\n",
        "\n",
        "## 📌 Steps Involved\n",
        "1. **Load Data**\n",
        "   - Read Greeklish and English text files.\n",
        "   - Apply **text cleaning** (lowercase, remove special characters & URLs).\n",
        "\n",
        "2. **Data Augmentation**\n",
        "   - **Word Shuffling** → Randomly swap two words.\n",
        "   - **Synonym Replacement** → Replace words with their synonyms using **WordNet**.\n",
        "\n",
        "3. **Balancing the Dataset**\n",
        "   - Expand dataset to **5000 samples per class**.\n",
        "   - **Random duplication** of sentences to match target size.\n",
        "\n",
        "4. **Save Processed Data**\n",
        "   - Convert to **CSV format** (`balanced_augmented_dataset.csv`).\n",
        "   - Labels: **Greeklish (5000)** & **English (5000)**.\n"
      ],
      "metadata": {
        "id": "Sun7A02lJn0v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "k25SoxJXKJ6X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import re\n",
        "import random\n",
        "from nltk.corpus import wordnet\n",
        "import nltk\n",
        "\n",
        "nltk.download('wordnet')\n",
        "\n",
        "# ------------------ File Paths ------------------ #\n",
        "greeklish_files = [\"greeklish_data.txt\", \"greeklish_data1.txt\", \"my_reddit_feed.txt\"]\n",
        "english_files = [\"english_data.txt\"]\n",
        "\n",
        "# ------------------ Cleaning Function ------------------ #\n",
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r\"http\\S+|www\\S+\", \"\", text)\n",
        "    text = re.sub(r\"[^a-zA-Zα-ωΑ-Ω\\s]\", \"\", text)\n",
        "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
        "    return text\n",
        "\n",
        "# ------------------ Load & Clean Sentences ------------------ #\n",
        "def load_sentences(file_list):\n",
        "    all_sentences = []\n",
        "    for file in file_list:\n",
        "        if os.path.exists(file):\n",
        "            with open(file, \"r\", encoding=\"utf-8\") as f:\n",
        "                lines = f.readlines()\n",
        "                cleaned = [clean_text(line.strip()) for line in lines if len(line.strip().split()) > 4]\n",
        "                all_sentences.extend(cleaned)\n",
        "    return all_sentences\n",
        "\n",
        "# ------------------ Augmentation: Word Shuffling & Synonym Replacement ------------------ #\n",
        "def synonym_replace(sentence):\n",
        "    words = sentence.split()\n",
        "    new_sentence = []\n",
        "    for word in words:\n",
        "        synonyms = wordnet.synsets(word)\n",
        "        if synonyms:\n",
        "            new_word = synonyms[0].lemmas()[0].name().replace(\"_\", \" \")\n",
        "            new_sentence.append(new_word)\n",
        "        else:\n",
        "            new_sentence.append(word)\n",
        "    return \" \".join(new_sentence)\n",
        "\n",
        "def augment_sentences(sentences, n_augments=5):\n",
        "    augmented = []\n",
        "    for sentence in sentences:\n",
        "        words = sentence.split()\n",
        "        for _ in range(n_augments):\n",
        "            if len(words) > 2:\n",
        "                # Word Shuffling\n",
        "                idx1, idx2 = random.sample(range(len(words)), 2)\n",
        "                words_copy = words.copy()\n",
        "                words_copy[idx1], words_copy[idx2] = words_copy[idx2], words_copy[idx1]\n",
        "                new_sentence = \" \".join(words_copy)\n",
        "\n",
        "                # Synonym Replacement (50% probability)\n",
        "                if random.random() < 0.5:\n",
        "                    new_sentence = synonym_replace(new_sentence)\n",
        "\n",
        "                augmented.append(new_sentence)\n",
        "    return augmented\n",
        "\n",
        "# ------------------ Load and Augment ------------------ #\n",
        "greeklish_sentences = load_sentences(greeklish_files)\n",
        "english_sentences = load_sentences(english_files)\n",
        "\n",
        "aug_greeklish = augment_sentences(greeklish_sentences, n_augments=5)\n",
        "aug_english = augment_sentences(english_sentences, n_augments=5)\n",
        "\n",
        "all_greeklish = greeklish_sentences + aug_greeklish\n",
        "all_english = english_sentences + aug_english\n",
        "\n",
        "# ------------------ Expand to 5000 Samples Each ------------------ #\n",
        "def expand_to_target(sentences, target_size=5000):\n",
        "    while len(sentences) < target_size:\n",
        "        sentences += random.sample(sentences, min(len(sentences), target_size - len(sentences)))\n",
        "    return sentences[:target_size]\n",
        "\n",
        "all_greeklish = expand_to_target(all_greeklish, 5000)\n",
        "all_english = expand_to_target(all_english, 5000)\n",
        "\n",
        "# ------------------ Create DataFrame ------------------ #\n",
        "df = pd.DataFrame({\n",
        "    \"Sentence\": all_greeklish + all_english,\n",
        "    \"Label\": [\"Greeklish\"] * 5000 + [\"English\"] * 5000\n",
        "})\n",
        "\n",
        "# ------------------ Save to CSV ------------------ #\n",
        "df.to_csv(\"balanced_augmented_dataset.csv\", index=False, encoding=\"utf-8\")\n",
        "print(f\"✅ Saved balanced dataset with 5000 Greeklish and 5000 English samples.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9jySOWrKok7Q",
        "outputId": "95343df1-ef6d-4307-d684-5c8d720aa259"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved balanced dataset with 5000 Greeklish and 5000 English samples.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.shape)  # ✅ Correct\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Ywg6sXHgf_B",
        "outputId": "53c5fabe-3dd6-4a47-da44-01e63ebd0d30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10000, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 📌 Greeklish vs. English Classification using TF-IDF + Logistic Regression\n",
        "\n",
        "This notebook classifies text as **Greeklish or English** using **TF-IDF vectorization** and a **Logistic Regression model**. The dataset is loaded, vectorized with **unigrams and bigrams**, and split into training/testing sets. The model is trained on TF-IDF features and evaluated using accuracy and a classification report. Finally, the trained model and vectorizer are saved for future use. 🚀\n"
      ],
      "metadata": {
        "id": "ryoyYJiALhNV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import joblib\n",
        "\n",
        "# Load cleaned dataset\n",
        "df = pd.read_csv(\"balanced_augmented_dataset.csv\")\n",
        "\n",
        "# TF-IDF Vectorization\n",
        "vectorizer = TfidfVectorizer(ngram_range=(1, 2), max_features=5000)  # Unigrams & Bigrams\n",
        "X = vectorizer.fit_transform(df[\"Sentence\"])  # Convert text to numerical form\n",
        "y = df[\"Label\"]  # Target labels\n",
        "\n",
        "# Split into Training & Testing Data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Logistic Regression Classifier\n",
        "classifier = LogisticRegression()\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "# Model Evaluation\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"✅ Model Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Show Classification Report\n",
        "print(\"\\n🔹 Classification Report:\\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "# Save Model & Vectorizer for Future Use\n",
        "joblib.dump(classifier, \"text_classifier.pkl\")\n",
        "joblib.dump(vectorizer, \"tfidf_vectorizer.pkl\")\n",
        "\n",
        "print(\"✅ Model & Vectorizer saved successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pg39GFSUKNa_",
        "outputId": "d11f1f95-4e46-4480-8fec-06196df193f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Model Accuracy: 1.0000\n",
            "\n",
            "🔹 Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     English       1.00      1.00      1.00       988\n",
            "   Greeklish       1.00      1.00      1.00      1012\n",
            "\n",
            "    accuracy                           1.00      2000\n",
            "   macro avg       1.00      1.00      1.00      2000\n",
            "weighted avg       1.00      1.00      1.00      2000\n",
            "\n",
            "✅ Model & Vectorizer saved successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 📝 Greeklish vs. English Classification using LSTM\n",
        "\n",
        "This notebook trains an **LSTM-based neural network** to classify text as **Greeklish or English**. The dataset is tokenized and padded to ensure uniform input size. The model includes **embedding, LSTM layers, dropout for regularization, and batch normalization** to improve learning. After training, the model is evaluated and saved along with the tokenizer for future predictions. 🚀\n"
      ],
      "metadata": {
        "id": "8dl0mHBmLzeT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "from sklearn.model_selection import train_test_split\n",
        "import joblib\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv(\"balanced_augmented_dataset.csv\")\n",
        "\n",
        "# Convert labels to numbers (Greeklish = 1, English = 0)\n",
        "df[\"Label\"] = df[\"Label\"].map({\"Greeklish\": 1, \"English\": 0})\n",
        "\n",
        "# Tokenization (Convert words into numerical values)\n",
        "tokenizer = Tokenizer(num_words=5000, oov_token=\"<OOV>\")\n",
        "tokenizer.fit_on_texts(df[\"Sentence\"])\n",
        "X = tokenizer.texts_to_sequences(df[\"Sentence\"])\n",
        "\n",
        "# Padding sequences (ensures all inputs have the same length)\n",
        "X = pad_sequences(X, maxlen=50, padding=\"post\", truncating=\"post\")\n",
        "y = np.array(df[\"Label\"])\n",
        "\n",
        "# Split data (80% Train, 20% Test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Build LSTM Model\n",
        "#model = Sequential([\n",
        "#    Embedding(input_dim=5000, output_dim=128, input_length=50),\n",
        "#    LSTM(128, return_sequences=True),\n",
        "#    Dropout(0.2),\n",
        "#    LSTM(64),\n",
        "#    Dropout(0.2),\n",
        "#    Dense(1, activation=\"sigmoid\")  # Sigmoid for binary classification\n",
        "#])\n",
        "\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "\n",
        "model = Sequential([\n",
        "    Embedding(input_dim=5000, output_dim=128, input_length=50),\n",
        "    LSTM(128, return_sequences=True),\n",
        "    BatchNormalization(),  # Normalize activations\n",
        "    Dropout(0.3),\n",
        "    LSTM(64),\n",
        "    Dropout(0.3),\n",
        "    Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "\n",
        "\n",
        "# Compile Model\n",
        "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "# Train Model\n",
        "model.fit(X_train, y_train, epochs=25, batch_size=32, validation_data=(X_test, y_test))\n",
        "\n",
        "# Save Model & Tokenizer\n",
        "model.save(\"lstm_text_classifier.h5\")\n",
        "joblib.dump(tokenizer, \"tokenizer.pkl\")\n",
        "\n",
        "print(\"✅ Model & Tokenizer saved successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9dd4eRUnY9Iz",
        "outputId": "c26ca734-1166-4b1b-b06a-0e52887e563f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 123ms/step - accuracy: 0.8919 - loss: 0.2155 - val_accuracy: 1.0000 - val_loss: 0.0012\n",
            "Epoch 2/25\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 124ms/step - accuracy: 1.0000 - loss: 6.1363e-04 - val_accuracy: 1.0000 - val_loss: 1.5216e-04\n",
            "Epoch 3/25\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 123ms/step - accuracy: 1.0000 - loss: 2.3960e-04 - val_accuracy: 1.0000 - val_loss: 7.1448e-05\n",
            "Epoch 4/25\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 122ms/step - accuracy: 1.0000 - loss: 1.3627e-04 - val_accuracy: 1.0000 - val_loss: 4.7436e-05\n",
            "Epoch 5/25\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 127ms/step - accuracy: 1.0000 - loss: 9.9102e-05 - val_accuracy: 1.0000 - val_loss: 3.4138e-05\n",
            "Epoch 6/25\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 140ms/step - accuracy: 1.0000 - loss: 6.9697e-05 - val_accuracy: 1.0000 - val_loss: 2.5714e-05\n",
            "Epoch 7/25\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 122ms/step - accuracy: 1.0000 - loss: 5.4046e-05 - val_accuracy: 1.0000 - val_loss: 2.0360e-05\n",
            "Epoch 8/25\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 122ms/step - accuracy: 1.0000 - loss: 4.0707e-05 - val_accuracy: 1.0000 - val_loss: 1.6210e-05\n",
            "Epoch 9/25\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 122ms/step - accuracy: 1.0000 - loss: 3.5935e-05 - val_accuracy: 1.0000 - val_loss: 1.3202e-05\n",
            "Epoch 10/25\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 123ms/step - accuracy: 1.0000 - loss: 2.8897e-05 - val_accuracy: 1.0000 - val_loss: 1.0989e-05\n",
            "Epoch 11/25\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 123ms/step - accuracy: 1.0000 - loss: 2.2306e-05 - val_accuracy: 1.0000 - val_loss: 9.1851e-06\n",
            "Epoch 12/25\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 134ms/step - accuracy: 1.0000 - loss: 1.9224e-05 - val_accuracy: 1.0000 - val_loss: 7.7448e-06\n",
            "Epoch 13/25\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 123ms/step - accuracy: 1.0000 - loss: 1.6413e-05 - val_accuracy: 1.0000 - val_loss: 6.5032e-06\n",
            "Epoch 14/25\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 133ms/step - accuracy: 1.0000 - loss: 1.4283e-05 - val_accuracy: 1.0000 - val_loss: 5.4449e-06\n",
            "Epoch 15/25\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 133ms/step - accuracy: 1.0000 - loss: 1.1855e-05 - val_accuracy: 1.0000 - val_loss: 4.6140e-06\n",
            "Epoch 16/25\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 133ms/step - accuracy: 1.0000 - loss: 1.0108e-05 - val_accuracy: 1.0000 - val_loss: 3.8812e-06\n",
            "Epoch 17/25\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 123ms/step - accuracy: 1.0000 - loss: 9.3899e-06 - val_accuracy: 1.0000 - val_loss: 3.2543e-06\n",
            "Epoch 18/25\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 123ms/step - accuracy: 1.0000 - loss: 7.5146e-06 - val_accuracy: 1.0000 - val_loss: 2.7888e-06\n",
            "Epoch 19/25\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 123ms/step - accuracy: 1.0000 - loss: 6.6261e-06 - val_accuracy: 1.0000 - val_loss: 2.4232e-06\n",
            "Epoch 20/25\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 120ms/step - accuracy: 1.0000 - loss: 5.6200e-06 - val_accuracy: 1.0000 - val_loss: 2.0948e-06\n",
            "Epoch 21/25\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 123ms/step - accuracy: 1.0000 - loss: 5.2651e-06 - val_accuracy: 1.0000 - val_loss: 1.8196e-06\n",
            "Epoch 22/25\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 123ms/step - accuracy: 1.0000 - loss: 4.4038e-06 - val_accuracy: 1.0000 - val_loss: 1.5870e-06\n",
            "Epoch 23/25\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 122ms/step - accuracy: 1.0000 - loss: 3.8816e-06 - val_accuracy: 1.0000 - val_loss: 1.3825e-06\n",
            "Epoch 24/25\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 126ms/step - accuracy: 1.0000 - loss: 3.4761e-06 - val_accuracy: 1.0000 - val_loss: 1.2163e-06\n",
            "Epoch 25/25\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 121ms/step - accuracy: 1.0000 - loss: 3.0029e-06 - val_accuracy: 1.0000 - val_loss: 1.0633e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Model & Tokenizer saved successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.word_index)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mh-zM1S51-mc",
        "outputId": "025eb2a4-ab33-4956-8872-888e828cf068"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'<OOV>': 1, 'the': 2, 'to': 3, 'and': 4, 'of': 5, 'a': 6, 'that': 7, 'in': 8, 'on': 9, 'for': 10, 'angstrom': 11, 'be': 12, 'you': 13, 'with': 14, 'inch': 15, 'i': 16, 'του': 17, 'technology': 18, 'και': 19, 'by': 20, 'information': 21, 'have': 22, 'is': 23, 'not': 24, 'from': 25, 'state': 26, 'iodine': 27, 'israeli': 28, 'το': 29, 'it': 30, 'this': 31, 'greekchatgr': 32, 'να': 33, 'my': 34, 'are': 35, 'was': 36, 'if': 37, 'as': 38, 'said': 39, 'arsenic': 40, 'its': 41, 'what': 42, 'they': 43, 'all': 44, 'international': 45, 'about': 46, 'has': 47, 'person': 48, 'company': 49, 'were': 50, 'των': 51, 'your': 52, 'work': 53, 'την': 54, 'like': 55, 'gaza': 56, 'netanyahu': 57, 'more': 58, 'rich': 59, 'aid': 60, 'washington': 61, 'no': 62, 'but': 63, 'their': 64, 'im': 65, 'για': 66, 'since': 67, 'can': 68, 'out': 69, 'just': 70, 'one': 71, 'beryllium': 72, 'at': 73, 'people': 74, 'which': 75, 'would': 76, 'use': 77, 'an': 78, 'been': 79, 'canada': 80, 'get': 81, 'dont': 82, 'health': 83, 'there': 84, 'after': 85, 'court': 86, 'up': 87, 'merely': 88, 'some': 89, 'hungary': 90, 'που': 91, 'hour': 92, 'astatine': 93, 'israel': 94, 'had': 95, 'first': 96, 'τους': 97, 'into': 98, 'do': 99, 'decision': 100, 'angle': 101, 'than': 102, 'need': 103, 'over': 104, 'icc': 105, 'war': 106, 'because': 107, 'will': 108, 'time': 109, 'associate': 110, 'commerce': 111, 'or': 112, 'nursing': 113, 'military': 114, 'occupation': 115, 'make': 116, 'law': 117, 'united': 118, 'ive': 119, 'he': 120, 'us': 121, 'software': 122, 'strip': 123, 'world': 124, 'σε': 125, 'force': 126, 'helium': 127, 'other': 128, 'them': 129, 'following': 130, 'prcs': 131, 'interstate': 132, 'commission': 133, 'humanitarian': 134, 'οι': 135, 'earlier': 136, 'oregon': 137, 'point': 138, 'prime': 139, 'απ': 140, 'emergency': 141, 'science': 142, 'statement': 143, 'states': 144, 'cnn': 145, 'με': 146, 'good': 147, 'warrant': 148, 'visit': 149, 'ο': 150, 'china': 151, 'think': 152, 'job': 153, 'δεν': 154, 'could': 155, 'τα': 156, 'area': 157, 'duty': 158, 'member': 159, 'we': 160, 'team': 161, 'της': 162, 'defense': 163, 'forces': 164, 'bash': 165, 'hours': 166, 'volition': 167, 'wednesday': 168, 'march': 169, 'jul': 170, 'carney': 171, 'well': 172, 'so': 173, 'new': 174, 'code': 175, 'trump': 176, 'worker': 177, 'under': 178, 'know': 179, 'very': 180, 'being': 181, 'υπηρεσες': 182, 'τι': 183, 'youre': 184, 'me': 185, 'organization': 186, 'should': 187, 'then': 188, 'house': 189, 'minister': 190, 'δικαωμα': 191, 'much': 192, 'attack': 193, 'week': 194, 'civil': 195, 'tariffs': 196, 'our': 197, 'when': 198, 'orban': 199, 'issue': 200, 'sunday': 201, 'vasile': 202, 'stancu': 203, 'sol': 204, 'workers': 205, 'thursday': 206, 'υπηρεσιν': 207, 'η': 208, 'hamas': 209, 'nations': 210, 'doing': 211, 'red': 212, 'criminal': 213, 'περιεχομνου': 214, 'also': 215, 'leader': 216, 'στο': 217, 'now': 218, 'government': 219, 'day': 220, 'end': 221, 'fire': 222, 'most': 223, 'who': 224, 'always': 225, 'call': 226, 'support': 227, 'χρστες': 228, 'στις': 229, 'enclave': 230, 'pm': 231, 'political': 232, 'attacks': 233, 'canadian': 234, 'told': 235, 'working': 236, 'month': 237, 'president': 238, 'general': 239, 'actually': 240, 'nether': 241, 'go': 242, 'two': 243, 'technical': 244, 'these': 245, 'killed': 246, 'εν': 247, 'thats': 248, 'office': 249, 'back': 250, 'bodies': 251, 'rafah': 252, 'stopping': 253, 'foreign': 254, 'sand': 255, 'last': 256, 'did': 257, 'fentanyl': 258, 'curate': 259, 'move': 260, 'white': 261, 'southern': 262, 'body': 263, 'must': 264, 'χρστης': 265, 'even': 266, 'his': 267, 'unocha': 268, 'evening': 269, 'want': 270, 'crescent': 271, 'εναι': 272, 'organizations': 273, 'europe': 274, 'business': 275, 'important': 276, 'less': 277, 'crime': 278, 'maine': 279, 'during': 280, 'year': 281, 'site': 282, 'global': 283, 'χρστη': 284, 'χρση': 285, 'computer': 286, 'money': 287, 'research': 288, 'canadas': 289, 'περιεχμενο': 290, 'keep': 291, 'while': 292, 'talk': 293, 'isnt': 294, 'staff': 295, 'arrest': 296, 'number': 297, 'am': 298, 'include': 299, 'clear': 300, 'here': 301, 'tax': 302, 'come': 303, 'right': 304, 'next': 305, 'dev': 306, 'take': 307, 'already': 308, 'part': 309, 'complex': 310, 'see': 311, 'how': 312, 'israels': 313, 'degree': 314, 'idf': 315, 'agency': 316, 'learn': 317, 'tue': 318, 'why': 319, 'medical': 320, 'any': 321, 'missing': 322, 'others': 323, 'companies': 324, 'vehicles': 325, 'expect': 326, 'ambulances': 327, 'τις': 328, 'same': 329, 'without': 330, 'before': 331, 'recovered': 332, 'τη': 333, 'economy': 334, 'market': 335, 'november': 336, 'economic': 337, 'show': 338, 'energy': 339, 'say': 340, 'besides': 341, 'whittall': 342, 'thing': 343, 'reach': 344, 'μπορε': 345, 'where': 346, 'repeatedly': 347, 'key': 348, 'according': 349, 'experience': 350, 'meeting': 351, 'news': 352, 'autopsy': 353, 'humanity': 354, 'october': 355, 'order': 356, 'un': 357, 'ceasefire': 358, 'including': 359, 'until': 360, 'against': 361, 'withdrawal': 362, 'assault': 363, 'way': 364, 'official': 365, 'hungarys': 366, 'secretary': 367, 'ambulance': 368, 'never': 369, 'engineering': 370, 'trade': 371, 'pretty': 372, 'target': 373, 'withdraw': 374, 'δεδομνων': 375, 'feel': 376, 'country': 377, 'προσωπικ': 378, 'better': 379, 'search': 380, 'χρσης': 381, 'χει': 382, 'wage': 383, 'fake': 384, 'complete': 385, 'privation': 386, 'kill': 387, 'αυτ': 388, 'theyre': 389, 'junior': 390, 'months': 391, 'federal': 392, 'americium': 393, 'calendar': 394, 'στους': 395, 'περπτωση': 396, 'anything': 397, 'look': 398, 'medic': 399, 'down': 400, 'τρπο': 401, 'him': 402, 'condemned': 403, 'οποιαδποτε': 404, 'really': 405, 'both': 406, 'apprehension': 407, 'consequence': 408, 'hospital': 409, 'question': 410, 'enough': 411, 'those': 412, 'something': 413, 'x': 414, 'things': 415, 'give': 416, 'mean': 417, 'lone': 418, 'open': 419, 'today': 420, 'morning': 421, 'only': 422, 'τον': 423, 'across': 424, 'set': 425, 'act': 426, 'καμα': 427, 'travel': 428, 'add': 429, 'response': 430, 'universe': 431, 'χωρς': 432, 'video': 433, 'field': 434, 'discovery': 435, 'στην': 436, 'find': 437, 'several': 438, 'group': 439, 'learning': 440, 'least': 441, 'kind': 442, 'society': 443, 'monday': 444, 'return': 445, 'tech': 446, 'strong': 447, 'αποκλειστικ': 448, 'again': 449, 'care': 450, 'many': 451, 'products': 452, 'own': 453, 'night': 454, 'developer': 455, 'school': 456, 'communication': 457, 'getting': 458, 'saying': 459, 'executive': 460, 'terrorist': 461, 'still': 462, 'data': 463, 'myself': 464, 'bad': 465, 'worth': 466, 'accuse': 467, 'επεξεργασας': 468, 'director': 469, 'effect': 470, 'bulldozer': 471, 'trying': 472, 'does': 473, 'real': 474, 'help': 475, 'ten': 476, 'checkup': 477, 'union': 478, 'netanyahus': 479, 'στοιχεα': 480, 'become': 481, 'later': 482, 'miss': 483, 'everything': 484, 'hand': 485, 'hit': 486, 'start': 487, 'try': 488, 'impact': 489, 'stance': 490, 'times': 491, 'chief': 492, 'officer': 493, 'feb': 494, 'means': 495, 'continue': 496, 'national': 497, 'spokesman': 498, 'remains': 499, 'protected': 500, 'χρηστν': 501, 'particular': 502, 'old': 503, 'coordination': 504, 'πως': 505, 'pull': 506, 'ocha': 507, 'services': 508, 'goods': 509, 'recover': 510, 'done': 511, 'διατηρε': 512, 'expected': 513, 'basically': 514, 'saar': 515, 'moral': 516, 'hungarian': 517, 'palestine': 518, 'nine': 519, 'pcrs': 520, 'punishable': 521, 'apply': 522, 'felt': 523, 'large': 524, 'manner': 525, 'ongoing': 526, 'among': 527, 'announcement': 528, 'leave': 529, 'follow': 530, 'function': 531, 'between': 532, 'may': 533, 'north': 534, 'mass': 535, 'grave': 536, 'head': 537, 'cabinet': 538, 'positive': 539, 'δημοσευση': 540, 'range': 541, 'incident': 542, 'μη': 543, 'interview': 544, 'jobs': 545, 'put': 546, 'crimes': 547, 'donald': 548, 'deadly': 549, 'vote': 550, 'protect': 551, 'ρους': 552, 'productive': 553, 'therefore': 554, 'ministers': 555, 'bury': 556, 'ifrc': 557, 'tuesday': 558, 'αρχ': 559, 'answer': 560, 'authority': 561, 'mark': 562, 'dispatched': 563, 'independently': 564, 'bullet': 565, 'tank': 566, 'levies': 567, 'levy': 568, 'μην': 569, 'senior': 570, 'deal': 571, 'idea': 572, 'change': 573, 'opinion': 574, 'symbolic': 575, 'rome': 576, 'every': 577, 'departure': 578, 'accused': 579, 'vehicle': 580, 'lead': 581, 'treaty': 582, 'announce': 583, 'hire': 584, 'engineer': 585, 'development': 586, 'few': 587, 'ceo': 588, 'meet': 589, 'facilities': 590, 'θα': 591, 'spend': 592, 'problem': 593, 'batch': 594, 'through': 595, 'truly': 596, 'added': 597, 'targeting': 598, 'harmonize': 599, 'doesnt': 600, 'announced': 601, 'digging': 602, 'οποιοδποτε': 603, 'looking': 604, 'etc': 605, 'lot': 606, 'using': 607, 'line': 608, 'μσω': 609, 'δεδομνα': 610, 'ask': 611, 'thinking': 612, 'unless': 613, 'operation': 614, 'wed': 615, 'passion': 616, 'theres': 617, 'semen': 618, 'department': 619, 'κθε': 620, 'cookie': 621, 'army': 622, 'described': 623, 'reached': 624, 'auto': 625, 'οποιονδποτε': 626, 'early': 627, 'yourself': 628, 'cut': 629, 'publish': 630, 'rather': 631, 'genuine': 632, 'side': 633, 'claimed': 634, 'conflict': 635, 'targeted': 636, 'describe': 637, 'attempt': 638, 'terrorists': 639, 'personnel': 640, 'measures': 641, 'intern': 642, 'victims': 643, 'youll': 644, 'ai': 645, 'pain': 646, 'made': 647, 'standard': 648, 'meanwhile': 649, 'rules': 650, 'leadership': 651, 'came': 652, 'february': 653, 'got': 654, 'palestinian': 655, 'going': 656, 'devs': 657, 'structural': 658, 'likely': 659, 'free': 660, 'drive': 661, 'entry': 662, 'επισκπτηςχρστης': 663, 'σας': 664, 'base': 665, 'lapp': 666, 'προβε': 667, 'λογαριασμο': 668, 'let': 669, 'alongside': 670, 'civilian': 671, 'νμο': 672, 'similar': 673, 'past': 674, 'scale': 675, 'life': 676, 'meant': 677, 'nothing': 678, 'interest': 679, 'phase': 680, 'bedwere': 681, 'graduate': 682, 'system': 683, 'uns': 684, 'αυτο': 685, 'sun': 686, 'home': 687, 'building': 688, 'industry': 689, 'opportunity': 690, 'box': 691, 'evidence': 692, 'tariff': 693, 'pay': 694, 'able': 695, 'wrong': 696, 'difficult': 697, 'occupied': 698, 'mechanism': 699, 'items': 700, 'moment': 701, 'havent': 702, 'statute': 703, 'seen': 704, 'struck': 705, 'trumps': 706, 'ευθνη': 707, 'amplaos': 708, 'resources': 709, 'seems': 710, 'roles': 711, 'power': 712, 'legal': 713, 'jurisdiction': 714, 'condemn': 715, 'years': 716, 'figure': 717, 'intense': 718, 'advice': 719, 'feedback': 720, 'sum': 721, 'iccs': 722, 'issued': 723, 'victim': 724, 'κατανοε': 725, 'αποδχεται': 726, 'μεταφορ': 727, 'sat': 728, 'manager': 729, 'didnt': 730, 'project': 731, 'having': 732, 'masters': 733, 'hope': 734, 'found': 735, 'brand': 736, 'too': 737, 'boot': 738, 'measure': 739, 'enforce': 740, 'medics': 741, 'border': 742, 'αποστολ': 743, 'off': 744, 'σχετικ': 745, 'web': 746, 'motivation': 747, 'skill': 748, 'col': 749, 'path': 750, 'rule': 751, 'offer': 752, 'inside': 753, 'application': 754, 'places': 755, 'position': 756, 'heavy': 757, 'park': 758, 'went': 759, 'σελδων': 760, 'big': 761, 'killing': 762, 'five': 763, 'another': 764, 'respect': 765, 'tons': 766, 'loss': 767, 'employee': 768, 'list': 769, 'undertaking': 770, 'footing': 771, 'senators': 772, 'network': 773, 'εγγυται': 774, 'specific': 775, 'asking': 776, 'airport': 777, 'needs': 778, 'numbers': 779, 'technically': 780, 'werent': 781, 'intelligence': 782, 'palestinians': 783, 'leaders': 784, 'strike': 785, 'λγους': 786, 'συνομιλα': 787, 'throughout': 788, 'might': 789, 'name': 790, 'poor': 791, 'above': 792, 'regularly': 793, 'success': 794, 'mail': 795, 'warrants': 796, 'μνο': 797, 'parts': 798, 'option': 799, 'purpose': 800, 'crews': 801, 'επσης': 802, 'μεση': 803, 'υποκεμενο': 804, 'infrastructure': 805, 'honestly': 806, 'else': 807, 'scientific': 808, 'yet': 809, 'quiet': 810, 'send': 811, 'weapon': 812, 'resolution': 813, 'χρησιμοποιε': 814, 'χουν': 815, 'σμφωνα': 816, 'relationship': 817, 'scarcity': 818, 'solutions': 819, 'largely': 820, 'διαγραφ': 821, 'passionate': 822, 'focus': 823, 'high': 824, 'current': 825, 'profit': 826, 'terms': 827, 'prove': 828, 'age': 829, 'acquiring': 830, 'death': 831, 'noncompliant': 832, 'λλο': 833, 'anyone': 834, 'taking': 835, 'resource': 836, 'university': 837, 'remote': 838, 'alleged': 839, 'opened': 840, 'advancing': 841, 'excavation': 842, 'πρσβαση': 843, 'στε': 844, 'ρων': 845, 'mahasacham': 846, 'once': 847, 'cant': 848, 'significantly': 849, 'maybe': 850, 'outside': 851, 'murder': 852, 'choose': 853, 'mourn': 854, 'emts': 855, 'buried': 856, 'violate': 857, 'facility': 858, 'reporter': 859, 'προς': 860, 'πληροφορες': 861, 'ζημα': 862, 'χι': 863, 'used': 864, 'aws': 865, 'wasnt': 866, 'management': 867, 'establish': 868, 'responders': 869, 'approach': 870, 'dispatch': 871, 'ετε': 872, 'ψευδ': 873, 'car': 874, 'stuff': 875, 'camp': 876, 'huge': 877, 'update': 878, 'benjamin': 879, 'sought': 880, 'arrived': 881, 'continues': 882, 'officials': 883, 'δε': 884, 'διατηρον': 885, 'λλη': 886, 'anymore': 887, 'short': 888, 'involved': 889, 'lashkar': 890, 'e': 891, 'taiba': 892, 'renewed': 893, 'language': 894, 'solve': 895, 'wanted': 896, 'late': 897, 'figures': 898, 'claim': 899, 'story': 900, 'wide': 901, 'atlantic': 902, 'marks': 903, 'trip': 904, 'εγκατσταση': 905, 'saturday': 906, 'self': 907, 'dollar': 908, 'prosecute': 909, 'policy': 910, 'critical': 911, 'sovereignty': 912, 'fadi': 913, 'elabdullah': 914, 'bbc': 915, 'dodging': 916, 'προστασα': 917, 'παραβιζει': 918, 'aug': 919, 'welcome': 920, 'course': 921, 'best': 922, 'ph': 923, 'd': 924, 'possibly': 925, 'criticism': 926, 'politically': 927, 'precedent': 928, 'abandon': 929, 'justice': 930, 'authorities': 931, 'troops': 932, 'nasser': 933, 'παρντος': 934, 'however': 935, 'game': 936, 'highly': 937, 'shit': 938, 'space': 939, 'gideon': 940, 'germany': 941, 'coordinate': 942, 'retrieval': 943, 'weeklong': 944, 'rescue': 945, 'machinery': 946, 'unearth': 947, 'scene': 948, 'package': 949, 'sector': 950, 'art': 951, 'προσωπικν': 952, 'enjoy': 953, 'raise': 954, 'whole': 955, 'career': 956, 'busy': 957, 'secret': 958, 'european': 959, 'hague': 960, 'although': 961, 'annalena': 962, 'baerbock': 963, 'toward': 964, 'prior': 965, 'cbn': 966, 'bn': 967, 'wine': 968, 'orange': 969, 'juice': 970, 'inflict': 971, 'retaliatory': 972, 'handout': 973, 'declaration': 974, 'truck': 975, 'someone': 976, 'align': 977, 'within': 978, 'produce': 979, 'id': 980, 'usa': 981, 'productiveness': 982, 'sketch': 983, 'bring': 984, 'soon': 985, 'corrupt': 986, 'spoken': 987, 'eight': 988, 'trucks': 989, 'investigate': 990, 'lt': 991, 'nadav': 992, 'shoshani': 993, 'randomly': 994, 'debris': 995, 'decomposition': 996, 'courtesy': 997, 'eyes': 998, 'toll': 999, 'grim': 1000, 'milestone': 1001, 'sight': 1002, 'candace': 1003, 'laing': 1004, 'chamber': 1005, 'waking': 1006, 'uncertainty': 1007, 'chain': 1008, 'reaction': 1009, 'countertariffs': 1010, 'extent': 1011, 'telephone': 1012, 'grant': 1013, 'reprieve': 1014, 'previously': 1015, 'independence': 1016, 'available': 1017, 'sovereign': 1018, 'comprehensive': 1019, 'pound': 1020, 'bipartisan': 1021, 'justify': 1022, 'interviews': 1023, 'sign': 1024, 'request': 1025, 'viktor': 1026, 'orbans': 1027, 'visited': 1028, 'kristof': 1029, 'szalaybobrovniczky': 1030, 'budapest': 1031, 'six': 1032, 'sudden': 1033, 'incursion': 1034, 'jihad': 1035, 'jagan': 1036, 'chapagain': 1037, 'ahead': 1038, 'crisis': 1039, 'together': 1040, 'outline': 1041, 'carneys': 1042, 'liberal': 1043, 'virtually': 1044, 'flavio': 1045, 'volpe': 1046, 'automotive': 1047, 'association': 1048, 'ontario': 1049, 'doug': 1050, 'ford': 1051, 'queens': 1052, 'σχετικν': 1053, 'διεθυνση': 1054, 'οποες': 1055, 'easy': 1056, 'python': 1057, 'net': 1058, 'kelvin': 1059, 'expression': 1060, 'judges': 1061, 'reasonable': 1062, 'bore': 1063, 'joint': 1064, 'conference': 1065, 'clearly': 1066, 'hailed': 1067, 'bold': 1068, 'principled': 1069, 'socalled': 1070, 'fundamental': 1071, 'selfdefence': 1072, 'broad': 1073, 'korea': 1074, 'she': 1075, 'jonathan': 1076, 'rafahs': 1077, 'alhashashin': 1078, 'dr': 1079, 'marwan': 1080, 'elhems': 1081, 'activity': 1082, 'block': 1083, 'pressure': 1084, 'extension': 1085, 'speaking': 1086, 'parliament': 1087, 'hill': 1088, 'steel': 1089, 'aluminum': 1090, 'muchhyped': 1091, 'wrench': 1092, 'election': 1093, 'campaign': 1094, 'winnipeg': 1095, 'ottawa': 1096, 'convene': 1097, 'virtual': 1098, 'canadaus': 1099, 'relations': 1100, 'council': 1101, 'currency': 1102, 'republican': 1103, 'mitch': 1104, 'mcconnell': 1105, 'susan': 1106, 'collins': 1107, 'lisa': 1108, 'murkowski': 1109, 'rand': 1110, 'paul': 1111, 'aisle': 1112, 'rebuke': 1113, 'speaker': 1114, 'johnson': 1115, 'forum': 1116, 'αυτς': 1117, 'cost': 1118, 'everyone': 1119, 'certification': 1120, 'merchandise': 1121, 'fifteenth': 1122, 'initially': 1123, 'rd': 1124, 'factfinding': 1125, 'spokesperson': 1126, 'utmost': 1127, 'importance': 1128, 'weekslong': 1129, 'hamascontrolled': 1130, 'ministry': 1131, 'enter': 1132, 'ochas': 1133, 'latest': 1134, 'σκοπ': 1135, 'k': 1136, 'left': 1137, 'cs': 1138, 'love': 1139, 'hell': 1140, 'understand': 1141, 'share': 1142, 'role': 1143, 'fight': 1144, 'genocide': 1145, 'west': 1146, 'bank': 1147, 'east': 1148, 'jerusalem': 1149, 'federation': 1150, 'cross': 1151, 'single': 1152, 'decade': 1153, 'amid': 1154, 'blockade': 1155, 'onemonth': 1156, 'blocking': 1157, 'flow': 1158, 'starvation': 1159, 'hurdles': 1160, 'uninhabited': 1161, 'planning': 1162, 'resourcebased': 1163, 'none': 1164, 'comply': 1165, 'continental': 1166, 'agreement': 1167, 'potash': 1168, 'face': 1169, 'εγγραφ': 1170, 'δηλσει': 1171, 'στον': 1172, 'social': 1173, 'μηνυμτων': 1174, 'δναται': 1175, 'ως': 1176, 'operating': 1177, 'mission': 1178, 'man': 1179, 'essential': 1180, 'break': 1181, 'scalable': 1182, 'youd': 1183, 'applications': 1184, 'physics': 1185, 'necktie': 1186, 'imperativeness': 1187, 'carry': 1188, 'weight': 1189, 'operational': 1190, 'capacity': 1191, 'article': 1192, 'updated': 1193, 'exemption': 1194, 'theatrical': 1195, 'unveiling': 1196, 'unfair': 1197, 'afternoon': 1198, 'absent': 1199, 'ally': 1200, 'mexico': 1201, 'elements': 1202, 'bilateral': 1203, 'trading': 1204, 'κατ': 1205, 'επιθυμε': 1206, 'λες': 1207, 'κποιος': 1208, 'αν': 1209, 'τρτων': 1210, 'προσβλητικ': 1211, 'επεξεργασα': 1212, 'αντιρρσεις': 1213, 'αντιρρσεων': 1214, 'σελδες': 1215, 'street': 1216, 'internal': 1217, 'beyond': 1218, 'infinite': 1219, 'biology': 1220, 'groups': 1221, 'security': 1222, 'foot': 1223, 'εφσον': 1224, 'υποχρωση': 1225, 'λγω': 1226, 'reality': 1227, 'family': 1228, 'taken': 1229, 'writing': 1230, 'bro': 1231, 'productivity': 1232, 'model': 1233, 'germanys': 1234, 'unite': 1235, 'internet': 1236, 'καννα': 1237, 'υπεθυνος': 1238, 'προθησης': 1239, 'διαγρφουν': 1240, 'random': 1241, 'probably': 1242, 'win': 1243, 'released': 1244, 'small': 1245, 'skills': 1246, 'weekend': 1247, 'solution': 1248, 'true': 1249, 'guy': 1250, 'background': 1251, 'founding': 1252, 'counts': 1253, 'nation': 1254, 'proceedings': 1255, 'shut': 1256, 'wrote': 1257, 'distracted': 1258, 'margins': 1259, 'math': 1260, 'invite': 1261, 'συμφωνε': 1262, 'α': 1263, 'β': 1264, 'αντικεμενο': 1265, 'εικνων': 1266, 'φορων': 1267, 'great': 1268, 'personally': 1269, 'smaller': 1270, 'india': 1271, 'offshoring': 1272, 'applied': 1273, 'player': 1274, 'pass': 1275, 'insisted': 1276, 'affairs': 1277, 'bulldozers': 1278, 'battered': 1279, 'eliminated': 1280, 'islamic': 1281, 'militants': 1282, 'firing': 1283, 'repeated': 1284, 'purposes': 1285, 'spirits': 1286, 'pledged': 1287, 'lifts': 1288, 'crew': 1289, 'διαθσιμο': 1290, 'βλβης': 1291, 'εκ': 1292, 'ανλικους': 1293, 'ποινικ': 1294, 'αδκημα': 1295, 'insurance': 1296, 'legitimately': 1297, 'contract': 1298, 'product': 1299, 'screen': 1300, 'production': 1301, 'wouldnt': 1302, 'happen': 1303, 'fuck': 1304, 'scientists': 1305, 'cool': 1306, 'direction': 1307, 'hospitals': 1308, 'internship': 1309, 'excessively': 1310, 'signal': 1311, 'pushed': 1312, 'depressed': 1313, 'respondent': 1314, 'evasion': 1315, 'παρχει': 1316, 'επισκπτεςχρστες': 1317, 'δημσια': 1318, 'νομικ': 1319, 'δικαιματα': 1320, 'αρμδιοι': 1321, 'συνεργτες': 1322, 'πνευματικ': 1323, 'σματα': 1324, 'asked': 1325, 'ago': 1326, 'performance': 1327, 'obviously': 1328, 'post': 1329, 'salesforce': 1330, 'main': 1331, 'accurate': 1332, 'material': 1333, 'mention': 1334, 'transferred': 1335, 'staffs': 1336, 'assessment': 1337, 'investigation': 1338, 'adding': 1339, 'maintaining': 1340, 'engages': 1341, 'paramedics': 1342, 'territories': 1343, 'accusing': 1344, 'countermeasures': 1345, 'benzoin': 1346, 'seek': 1347, 'arrive': 1348, 'allege': 1349, 'σχετικς': 1350, 'μσα': 1351, 'δλωση': 1352, 'διακψει': 1353, 'οποιουδποτε': 1354, 'παρντες': 1355, 'δικαου': 1356, 'amount': 1357, 'tell': 1358, 'took': 1359, 'access': 1360, 'sure': 1361, 'faced': 1362, 'demand': 1363, 'principle': 1364, 'reference': 1365, 'showed': 1366, 'reporters': 1367, 'assert': 1368, 'advance': 1369, 'λο': 1370, 'τμματος': 1371, 'size': 1372, 'around': 1373, 'thought': 1374, 'ill': 1375, 'surprise': 1376, 'crap': 1377, 'institution': 1378, 'russia': 1379, 'recognise': 1380, 'violating': 1381, 'restricting': 1382, 'creating': 1383, 'attracted': 1384, 'mike': 1385, 'unlikely': 1386, 'regenerate': 1387, 'αναρτται': 1388, 'προστασας': 1389, 'interests': 1390, 'rattle': 1391, 'app': 1392, 'sick': 1393, 'ended': 1394, 'funding': 1395, 'fired': 1396, 'resume': 1397, 'says': 1398, 'centigrade': 1399, 'income': 1400, 'indicates': 1401, 'searched': 1402, 'colleagues': 1403, 'mon': 1404, 'challenges': 1405, 'started': 1406, 'phd': 1407, 'quality': 1408, 'knows': 1409, 'failure': 1410, 'procedure': 1411, 'cesium': 1412, 'mr': 1413, 'followed': 1414, 'procedures': 1415, 'issuance': 1416, 'recalls': 1417, 'cooperate': 1418, 'bias': 1419, 'committedness': 1420, 'alliance': 1421, 'disagreement': 1422, 'feels': 1423, 'coding': 1424, 'personal': 1425, 'assigned': 1426, 'desire': 1427, 'discontinue': 1428, 'aboard': 1429, 'written': 1430, 'notification': 1431, 'established': 1432, 'barrage': 1433, 'foray': 1434, 'harbor': 1435, 'agent': 1436, 'interviewer': 1437, 'situation': 1438, 'c': 1439, 'fresh': 1440, 'develop': 1441, 'gusto': 1442, 'cultivate': 1443, 'adopt': 1444, 'perceive': 1445, 'chance': 1446, 'calling': 1447, 'practice': 1448, 'suppose': 1449, 'instead': 1450, 'opportunities': 1451, 'members': 1452, 'sociable': 1453, 'thanked': 1454, 'eu': 1455, 'applies': 1456, 'areas': 1457, 'argued': 1458, 'minuscule': 1459, 'published': 1460, 'globe': 1461, 'attributed': 1462, 'seized': 1463, 'seizures': 1464, 'believe': 1465, 'examination': 1466, 'επιλογν': 1467, 'περιεχομνων': 1468, 'περιεχμενα': 1469, 'παρχονται': 1470, 'entire': 1471, 'especially': 1472, 'infinitely': 1473, 'loud': 1474, 'superintendent': 1475, 'soil': 1476, 'shovel': 1477, 'erosion': 1478, 'vest': 1479, 'screening': 1480, 'besiege': 1481, 'balker': 1482, 'senator': 1483, 'στη': 1484, 'businesses': 1485, 'almost': 1486, 'paying': 1487, 'low': 1488, 'met': 1489, 'express': 1490, 'certain': 1491, 'medium': 1492, 'confirmed': 1493, 'gathered': 1494, 'uniforms': 1495, 'gloves': 1496, 'militarys': 1497, 'presidents': 1498, 'powers': 1499, 'remained': 1500, 'movement': 1501, 'migrants': 1502, 'democracy': 1503, 'administration': 1504, 'leery': 1505, 'headlight': 1506, 'proverb': 1507, 'lake': 1508, 'boundary': 1509, 'chat': 1510, 'στοιχεων': 1511, 'αρμδιες': 1512, 'αρχς': 1513, 'δνει': 1514, 'διαγρψουν': 1515, 'νομα': 1516, 'μητρο': 1517, 'interested': 1518, 'lied': 1519, 'finally': 1520, 'knowledge': 1521, 'stack': 1522, 'write': 1523, 'directly': 1524, 'august': 1525, 'living': 1526, 'steps': 1527, 'identified': 1528, 'technicians': 1529, 'gazas': 1530, 'injuring': 1531, 'dozens': 1532, 'besieging': 1533, 'breaking': 1534, 'injured': 1535, 'verifying': 1536, 'allow': 1537, 'journalists': 1538, 'surpassed': 1539, 'marking': 1540, 'accept': 1541, 'injure': 1542, 'defined': 1543, 'influence': 1544, 'υπ': 1545, 'ασφλειας': 1546, 'ττε': 1547, 'περιχουν': 1548, 'ευθνεται': 1549, 'deliver': 1550, 'talented': 1551, 'thoroughly': 1552, 'fraud': 1553, 'worked': 1554, 'along': 1555, 'total': 1556, 'close': 1557, 'microsoft': 1558, 'levels': 1559, 'multiple': 1560, 'sclerosis': 1561, 'alumnus': 1562, 'interruption': 1563, 'addition': 1564, 'ruled': 1565, 'accepted': 1566, 'follows': 1567, 'collapsed': 1568, 'entering': 1569, 'accepting': 1570, 'proceed': 1571, 'truce': 1572, 'teachers': 1573, 'doctors': 1574, 'nurses': 1575, 'countries': 1576, 'practices': 1577, 'noticeably': 1578, 'throw': 1579, 'fly': 1580, 'ιστοσελδα': 1581, 'επισκπτες': 1582, 'επισκπτης': 1583, 'πριν': 1584, 'λογαριασμ': 1585, 'επισκπτηχρστη': 1586, 'μλους': 1587, 'απο': 1588, 'browser': 1589, 'ρυθμσεις': 1590, 'υπεθυνοι': 1591, 'διαχειριστς': 1592, 'αφορον': 1593, 'απαντσει': 1594, 'επ': 1595, 'απντησ': 1596, 'ανωτρω': 1597, 'συγκεκριμνο': 1598, 'μορφς': 1599, 'επιλογς': 1600, 'συμπεριλαμβανομνων': 1601, 'αυτν': 1602, 'δικ': 1603, 'greek': 1604, 'phpbb': 1605, 'stay': 1606, 'circle': 1607, 'problems': 1608, 'gotten': 1609, 'given': 1610, 'potential': 1611, 'thousand': 1612, 'graduated': 1613, 'fundamentals': 1614, 'lower': 1615, 'handling': 1616, 'mind': 1617, 'piece': 1618, 'nobody': 1619, 'earth': 1620, 'media': 1621, 'stallion': 1622, 'withdrawing': 1623, 'denied': 1624, 'estimate': 1625, 'warn': 1626, 'προσεκτικ': 1627, 'υποχρεοται': 1628, 'κτω': 1629, 'αλλ': 1630, 'εκτς': 1631, 'προειδοποιε': 1632, 'εξ': 1633, 'αρχεων': 1634, 'λων': 1635, 'γκου': 1636, 'λθη': 1637, 'διαδικτου': 1638, 'jerk': 1639, 'solving': 1640, 'keeping': 1641, 'grad': 1642, 'top': 1643, 'excuse': 1644, 'scientist': 1645, 'worry': 1646, 'promise': 1647, 'chemistry': 1648, 'projects': 1649, 'pure': 1650, 'buzzword': 1651, 'taxed': 1652, 'imposed': 1653, 'rescinded': 1654, 'deduction': 1655, 'επσκεψη': 1656, 'ετν': 1657, 'εγγραφς': 1658, 'γ': 1659, 'ειδικτερα': 1660, 'καθς': 1661, 'δημοσιεει': 1662, 'θεωρηθε': 1663, 'ναν': 1664, 'υπολογιστ': 1665, 'μορφ': 1666, 'φρει': 1667, 'απευθνονται': 1668, 'εγγρφως': 1669, 'πρπει': 1670, 'ατημα': 1671, 'προβλπονται': 1672, 'γονες': 1673, 'συνιστ': 1674, 'ημερομηνα': 1675, 'γννησης': 1676, 'κθεση': 1677, 'ανηλκων': 1678, 'δικεται': 1679, 'διαθσει': 1680, 'insane': 1681, 'userfacing': 1682, 'warm': 1683, 'geico': 1684, 'apparently': 1685, 'lay': 1686, 'build': 1687, 'gonna': 1688, 'afraid': 1689, 'youve': 1690, 'heavily': 1691, 'her': 1692, 'reason': 1693, 'absolutely': 1694, 'investors': 1695, 'finite': 1696, 'yes': 1697, 'though': 1698, 'task': 1699, 'waiter': 1700, 'bachelor': 1701, 'cover': 1702, 'fighter': 1703, 'poised': 1704, 'industries': 1705, 'countrys': 1706, 'διαπιστωθε': 1707, 'πλρη': 1708, 'κατπιν': 1709, 'αποστλλεται': 1710, 'νμου': 1711, 'ρητ': 1712, 'δικτυακο': 1713, 'τπου': 1714, 'διθεση': 1715, 'fun': 1716, 'literally': 1717, 'unfortunately': 1718, 'whats': 1719, 'paid': 1720, 'cloud': 1721, 'based': 1722, 'mess': 1723, 'feature': 1724, 'ceos': 1725, 'programming': 1726, 'analyst': 1727, 'institutions': 1728, 'understanding': 1729, 'reading': 1730, 'documentation': 1731, 'nowhere': 1732, 'heres': 1733, 'linkedin': 1734, 'stand': 1735, 'πλρως': 1736, 'βντεο': 1737, 'τυχν': 1738, 'ρθρο': 1739, 'ατμου': 1740, 'προσωπικο': 1741, 'χαρακτρα': 1742, 'υπεθυνο': 1743, 'προσωριν': 1744, 'οφελει': 1745, 'απαγορεεται': 1746, 'ελγχει': 1747, 'παρνομου': 1748, 'προειδοποηση': 1749, 'βσει': 1750, 'λλης': 1751, 'μεθδου': 1752, 'πνευματικς': 1753, 'ιδιοκτησας': 1754, 'συνεργατν': 1755, 'αποτελον': 1756, 'ιδιοκτησα': 1757, 'συνεπς': 1758, 'εμπορικ': 1759, 'φρουν': 1760, 'jeidsath': 1761, 'supposed': 1762, 'hard': 1763, 'mostly': 1764, 'salary': 1765, 'teach': 1766, 'apartment': 1767, 'argument': 1768, 'developers': 1769, 'bioinformatics': 1770, 'cakewalk': 1771, 'regardless': 1772, 'elsewhere': 1773, 'landing': 1774, 'different': 1775, 'recognize': 1776, 'necessitate': 1777, 'twelve': 1778, 'oppress': 1779, 'λλων': 1780, 'δ': 1781, 'διατξεις': 1782, 'ευρωπακο': 1783, 'αποτελσει': 1784, 'σνολο': 1785, 'μρος': 1786, 'markos': 1787, 'honest': 1788, 'parents': 1789, 'barely': 1790, 'risk': 1791, 'term': 1792, 'options': 1793, 'conversation': 1794, 'friday': 1795, 'teams': 1796, 'via': 1797, 'retail': 1798, 'massive': 1799, 'extremely': 1800, 'related': 1801, 'importantly': 1802, 'guess': 1803, 'wild': 1804, 'alone': 1805, 'journey': 1806, 'alternatively': 1807, 'massacre': 1808, 'tragedy': 1809, 'zone': 1810, 'expand': 1811, 'chemical': 1812, 'straiten': 1813, 'american': 1814, 'ip': 1815, 'λλως': 1816, 'πρκληση': 1817, 'προσπου': 1818, 'προσβλητικο': 1819, 'ν': 1820, 'πλασιο': 1821, 'makes': 1822, 'mscs': 1823, 'days': 1824, 'run': 1825, 'shame': 1826, 'wetlab': 1827, 'everywhere': 1828, 'tough': 1829, 'techadjacent': 1830, 'challenge': 1831, 'atrocious': 1832, 'frequently': 1833, 'grounds': 1834, 'responsibility': 1835, 'antisemitic': 1836, 'efforts': 1837, 'voices': 1838, 'passed': 1839, 'invoked': 1840, 'imports': 1841, 'doomed': 1842, 'trample': 1843, 'harm': 1844, 'remark': 1845, 'item': 1846, 'heard': 1847, 'employer': 1848, 'millions': 1849, 'expose': 1850, 'lets': 1851, 'supply': 1852, 'finished': 1853, 'pulled': 1854, 'full': 1855, 'jump': 1856, 'little': 1857, 'client': 1858, 'anyhow': 1859, 'particularly': 1860, 'cognition': 1861, 'control': 1862, 'withdraws': 1863, 'defence': 1864, 'greeted': 1865, 'tarmac': 1866, 'welcoming': 1867, 'crushed': 1868, 'comment': 1869, 'respond': 1870, 'manufacturers': 1871, 'posted': 1872, 'result': 1873, 'greet': 1874, 'tarmacadam': 1875, 'manufacturer': 1876, 'voice': 1877, 'import': 1878, 'moving': 1879, 'details': 1880, 'transfer': 1881, 'choice': 1882, 'lucky': 1883, 'applying': 1884, 'attention': 1885, 'fullstack': 1886, 'expressed': 1887, 'outrage': 1888, 'occupations': 1889, 'considered': 1890, 'automobiles': 1891, 'expanded': 1892, 'distressing': 1893, 'americans': 1894, 'canadians': 1895, 'sprawling': 1896, 'islands': 1897, 'rattled': 1898, 'markets': 1899, 'devastate': 1900, 'manufacturing': 1901, 'hubs': 1902, 'economies': 1903, 'confine': 1904, 'slaughter': 1905, 'calamity': 1906, 'react': 1907, 'super': 1908, 'invested': 1909, 'output': 1910, 'games': 1911, 'matter': 1912, 'phds': 1913, 'stopped': 1914, 'invest': 1915, 'concern': 1916, 'entree': 1917, 'confront': 1918, 'liberation': 1919, 'rwanda': 1920, 'exploitation': 1921, 'lost': 1922, 'trampling': 1923, 'principles': 1924, 'zest': 1925, 'harming': 1926, 'dozen': 1927, 'nears': 1928, 'zones': 1929, 'clearer': 1930, 'civilians': 1931, 'humanitarians': 1932, 'stages': 1933, 'premiers': 1934, 'anti': 1935, 'semitic': 1936, 'legislative': 1937, 'indignation': 1938, 'sprawl': 1939, 'island': 1940, 'waste': 1941, 'fabrication': 1942, 'hub': 1943, 'servers': 1944, 'companys': 1945, 'bug': 1946, 'suggest': 1947, 'second': 1948, 'benefit': 1949, 'form': 1950, 'increase': 1951, 'institute': 1952, 'lately': 1953, 'positions': 1954, 'doctor': 1955, 'sucking': 1956, 'expecting': 1957, 'retain': 1958, 'flight': 1959, 'bit': 1960, 'fact': 1961, 'quitting': 1962, 'bachelors': 1963, 'saved': 1964, 'recharge': 1965, 'turn': 1966, 'broke': 1967, 'maintain': 1968, 'likes': 1969, 'stop': 1970, 'million': 1971, 'cryptography': 1972, 'idaho': 1973, 'topographic': 1974, 'detained': 1975, 'cookies': 1976, 'process': 1977, 'level': 1978, 'sphere': 1979, 'understood': 1980, 'biotech': 1981, 'professional': 1982, 'employers': 1983, 'relieve': 1984, 'imo': 1985, 'engineers': 1986, 'bigger': 1987, 'supposedly': 1988, 'needing': 1989, 'created': 1990, 'simply': 1991, 'selling': 1992, 'compared': 1993, 'workforce': 1994, 'programmer': 1995, 'cheap': 1996, 'cast': 1997, 'restrict': 1998, 'interrupt': 1999, 'bend': 2000, 'berth': 2001, 'fri': 2002, 'humans': 2003, 'pick': 2004, 'mistake': 2005, 'restricted': 2006, 'clients': 2007, 'comes': 2008, 'struggling': 2009, 'friends': 2010, 'review': 2011, 'press': 2012, 'decelerate': 2013, 'indian': 2014, 'presently': 2015, 'stairs': 2016, 'making': 2017, 'ideas': 2018, 'ones': 2019, 'slightly': 2020, 'networked': 2021, 'deploy': 2022, 'value': 2023, 'necessity': 2024, 'salvage': 2025, 'lull': 2026, 'delegate': 2027, 'aligns': 2028, 'broader': 2029, 'cultivated': 2030, 'ties': 2031, 'adopted': 2032, 'view': 2033, 'perceived': 2034, 'infringing': 2035, 'besieged': 2036, 'leading': 2037, 'suspicious': 2038, 'headlights': 2039, 'signals': 2040, 'strikes': 2041, 'estimated': 2042, 'included': 2043, 'unclear': 2044, 'influenced': 2045, 'requested': 2046, 'became': 2047, 'identify': 2048, 'technician': 2049, 'interim': 2050, 'excel': 2051, 'marker': 2052, 'motion': 2053, 'migrant': 2054, 'δεδομνης': 2055, 'φσης': 2056, 'οποιεσδποτε': 2057, 'συνθκες': 2058, 'συμπεριλαμβανομνης': 2059, 'περπτωσης': 2060, 'αμλειας': 2061, 'οποιασδποτε': 2062, 'υποστε': 2063, 'προβανει': 2064, 'πρωτοβουλα': 2065, 'ακριβς': 2066, 'εγγηση': 2067, 'εκπεφρασμνη': 2068, 'συνεπαγμενη': 2069, 'μγιστο': 2070, 'βαθμ': 2071, 'αρνεται': 2072, 'εγγυσεις': 2073, 'εκπεφρασμνες': 2074, 'συνεπαγμενες': 2075, 'μως': 2076, 'περιοριζμενων': 2077, 'συνεπγονται': 2078, 'εμπορευσιμτητα': 2079, 'καταλληλτητα': 2080, 'διακοπ': 2081, 'σφλματα': 2082, 'διορθνονται': 2083, 'διο': 2084, 'συγγενικ': 2085, 'εξυπηρετητς': 2086, 'οποων': 2087, 'τθενται': 2088, 'διθεσ': 2089, 'επισκεπτνχρηστν': 2090, 'ιος': 2091, 'λλα': 2092, 'επιζμια': 2093, 'συστατικ': 2094, 'ορθτητα': 2095, 'πληρτητα': 2096, 'διαθεσιμτητα': 2097, 'αποτελσματ': 2098, 'κστος': 2099, 'ενδεχμενων': 2100, 'διορθσεων': 2101, 'εξυπηρετσεων': 2102, 'αναλαμβνει': 2103, 'ioannis': 2104, 'somewhere': 2105, 'highlevel': 2106, 'userbase': 2107, 'dream': 2108, 'intermittent': 2109, 'read': 2110, 'unrelated': 2111, 'lol': 2112, 'esnure': 2113, 'delivery': 2114, 'et': 2115, 'cetera': 2116, 'sending': 2117, 'replacement': 2118, 'ms': 2119, 'ton': 2120, 'courses': 2121, 'looks': 2122, 'wtf': 2123, 'quickly': 2124, 'becomes': 2125, 'assumption': 2126, 'prospect': 2127, 'discipline': 2128, 'supporting': 2129, 'tickles': 2130, 'peripheries': 2131, 'tend': 2132, 'filled': 2133, 'assholery': 2134, 'worklife': 2135, 'balance': 2136, 'lowball': 2137, 'responsible': 2138, 'soft': 2139, 'secondly': 2140, 'lane': 2141, 'double': 2142, 'excellent': 2143, 'internally': 2144, 'leverage': 2145, 'willingness': 2146, 'humble': 2147, 'nor': 2148, 'wiggle': 2149, 'room': 2150, 'cutthroat': 2151, 'getgo': 2152, 'wholly': 2153, 'precedence': 2154, 'investor': 2155, 'democracies': 2156, 'organisation': 2157, 'thrown': 2158, 'flew': 2159, 'thank': 2160, 'deny': 2161, 'gather': 2162, 'uniform': 2163, 'baseball': 2164, 'glove': 2165, 'siege': 2166, 'collapse': 2167, 'entrance': 2168, 'armistice': 2169, 'poise': 2170, 'revoke': 2171, 'συλλγει': 2172, 'ταν': 2173, 'πρα': 2174, 'πραγματικ': 2175, 'χρνο': 2176, 'τπο': 2177, 'δημσιας': 2178, 'σηζτησης': 2179, 'κοινωνικ': 2180, 'δκτυο': 2181, 'καταγρφει': 2182, 'αποστλλονται': 2183, 'διαπστωση': 2184, 'παραβσεων': 2185, 'προβλπεται': 2186, 'κανναν': 2187, 'γνωστοποισει': 2188, 'τρτους': 2189, 'συντκτης': 2190, 'νμος': 2191, 'αρμδια': 2192, 'απαιτε': 2193, 'πχ': 2194, 'καθορζεται': 2195, 'παροχα': 2196, 'σνδεσης': 2197, 'οποας': 2198, 'ηυ': 2199, 'διαδκτυο': 2200, 'συνχεια': 2201, 'κρατεται': 2202, 'τεχνικος': 2203, 'θματα': 2204, 'πτονται': 2205, 'συστημτων': 2206, 'greekchatgrgr': 2207, 'database': 2208, 'κλπ': 2209, 'παρλληλα': 2210, 'αξιοποιεται': 2211, 'συγκντρωση': 2212, 'στατιστικν': 2213, 'οποα': 2214, 'επικοιννησε': 2215, 'παραδοθε': 2216, 'αστυνομικς': 2217, 'δικαστικς': 2218, 'ζητηθε': 2219, 'διορθσουν': 2220, 'ενημερσουν': 2221, 'πσα': 2222, 'στιγμ': 2223, 'λβει': 2224, 'καταγγελα': 2225, 'ειδοποηση': 2226, 'οπουδποτε': 2227, 'παραβιζουν': 2228, 'προσπων': 2229, 'επιλξουν': 2230, 'επιθυμον': 2231, 'αρκε': 2232, 'πρστυχο': 2233, 'δηλνει': 2234, 'ερωτικς': 2235, 'προτιμσεις': 2236, 'υπλοιπους': 2237, 'δεσμεεται': 2238, 'πληση': 2239, 'ενοικαση': 2240, 'κοινοποηση': 2241, 'τρτο': 2242, 'φορα': 2243, 'διοχετεσει': 2244, 'εμπροθσμως': 2245, 'ικανοποιητικ': 2246, 'προσφγει': 2247, 'ζητσει': 2248, 'εξταση': 2249, 'αντιρρσεν': 2250, 'πιθανολογσει': 2251, 'ελογες': 2252, 'συντρχει': 2253, 'κνδυνος': 2254, 'σοβαρς': 2255, 'υποκειμνου': 2256, 'συνχιση': 2257, 'επιβλλει': 2258, 'αναστολ': 2259, 'εκδσει': 2260, 'οριστικ': 2261, 'απφαση': 2262, 'καθνας': 2263, 'αποτελσουν': 2264, 'πωλσεως': 2265, 'αγαθν': 2266, 'παροχς': 2267, 'αποστσεως': 2268, 'τηρε': 2269, 'ταυττητας': 2270, 'συμβουλεονται': 2271, 'αρχεο': 2272, 'πρσωπα': 2273, 'παραγρφου': 2274, 'τοτου': 2275, 'διαπιστσει': 2276, 'δημοσιετηκαν': 2277, 'φωτογραφες': 2278, 'προσβλλουν': 2279, 'παρακαλεται': 2280, 'επικοινωνσει': 2281, 'διενργεια': 2282, 'νμιμων': 2283, 'διαδικασιν': 2284, 'παραπνω': 2285, 'classical': 2286, 'customers': 2287, 'join': 2288, 'badly': 2289, 'anyway': 2290, 'bow': 2291, 'long': 2292, 'selftaught': 2293, 'looked': 2294, 'feeling': 2295, 'flood': 2296, 'warden': 2297, 'parole': 2298, 'outdated': 2299, 'message': 2300, 'dress': 2301, 'wear': 2302, 'sounds': 2303, 'blessing': 2304, 'disguise': 2305, 'needed': 2306, 'costs': 2307, 'quarters': 2308, 'modern': 2309, 'boards': 2310, 'bankroll': 2311, 'fewer': 2312, 'usbased': 2313, 'harder': 2314, 'systems': 2315, 'branch': 2316, 'cybersecurity': 2317, 'various': 2318, 'types': 2319, 'exist': 2320, 'relatively': 2321, 'relative': 2322, 'median': 2323, 'definitely': 2324, 'unemployed': 2325, 'spray': 2326, 'pray': 2327, 'opensource': 2328, 'azure': 2329, 'codeno': 2330, 'platform': 2331, 'sexy': 2332, 'traditional': 2333, 'developmentsoftware': 2334, 'ball': 2335, 'employment': 2336, 'trouble': 2337, 'cert': 2338, 'landed': 2339, 'preferable': 2340, 'prefer': 2341, 'acumen': 2342, 'qa': 2343, 'devops': 2344, 'swedev': 2345, 'obscure': 2346, 'fuzzed': 2347, 'operate': 2348, 'foreman': 2349, 'ohio': 2350, 'blindside': 2351, 'implications': 2352, 'alter': 2353, 'framework': 2354, 'shared': 2355, 'dirt': 2356, 'shovels': 2357, 'wearing': 2358, 'vests': 2359, 'showing': 2360, 'signs': 2361, 'enclaves': 2362, 'largest': 2363, 'functioning': 2364, 'bombardment': 2365, 'raids': 2366, 'harboring': 2367, 'operatives': 2368, 'saw': 2369, 'premier': 2370, 'coming': 2371, 'confirm': 2372, 'mister': 2373, 'recall': 2374, 'collaborate': 2375, 'bespeak': 2376, 'colleague': 2377, 'teacher': 2378, 'nurse': 2379, 'ολοκλρωση': 2380, 'διαδικασας': 2381, 'αποδοχς': 2382, 'εισλθει': 2383, 'παραμνουν': 2384, 'υπεθυνα': 2385, 'πρξεις': 2386, 'διενεργονται': 2387, 'υποχρεονται': 2388, 'ειδοποιον': 2389, 'μεσα': 2390, 'αντιληφθον': 2391, 'εξουσιοδοτημνη': 2392, 'πιθαν': 2393, 'παραβαση': 2394, 'ευθνονται': 2395, 'τυπικ': 2396, 'ξοδο': 2397, 'τλος': 2398, 'αναγνριση': 2399, 'ορισμνων': 2400, 'μικρ': 2401, 'κομμτι': 2402, 'αποθηκεεται': 2403, 'σκληρ': 2404, 'δσκο': 2405, 'αρχεου': 2406, 'txt': 2407, 'προκαλον': 2408, 'ζημι': 2409, 'σστημα': 2410, 'πλττουν': 2411, 'λειτουργικτητα': 2412, 'καθ': 2413, 'οιονδποτε': 2414, 'καθιστον': 2415, 'πλογηση': 2416, 'ευκολτερη': 2417, 'αποθηκεοντας': 2418, 'ρυθμσει': 2419, 'διακομιστ': 2420, 'ττοιο': 2421, 'συγκεκριμνες': 2422, 'επιτρπει': 2423, 'αποδοχ': 2424, 'συγκεκριμνων': 2425, 'αναγνρισ': 2426, 'ισχουν': 2427, 'πρτη': 2428, 'εσοδο': 2429, 'αποζημισει': 2430, 'διαμχη': 2431, 'προκψει': 2432, 'μεταξ': 2433, 'ανρτηση': 2434, 'swiftnicholas': 2435, 'homeric': 2436, 'poetry': 2437, 'misinterpret': 2438, 'approvesrejects': 2439, 'disservice': 2440, 'rewarding': 2441, 'stock': 2442, 'proud': 2443, 'multiplier': 2444, 'play': 2445, 's': 2446, 'abrupt': 2447, 'wakeup': 2448, 'slow': 2449, 'solver': 2450, 'confident': 2451, 'practically': 2452, 'useful': 2453, 'ability': 2454, 'weekly': 2455, 'outage': 2456, 'lunch': 2457, 'kingdom': 2458, 'wall': 2459, 'tired': 2460, 'savings': 2461, 'prepping': 2462, 'sue': 2463, 'mbatypes': 2464, 'humanly': 2465, 'possible': 2466, 'releases': 2467, 'openai': 2468, 'illusion': 2469, 'justification': 2470, 'goose': 2471, 'op': 2472, 'bing': 2473, 'engine': 2474, 'clean': 2475, 'garbage': 2476, 'meanhow': 2477, 'handle': 2478, 'mobile': 2479, 'each': 2480, 'reaching': 2481, 'computingcomputer': 2482, 'scienceprogramming': 2483, 'experienceinternship': 2484, 'statistics': 2485, 'delight': 2486, 'professor': 2487, 'lab': 2488, 'summer': 2489, 'graduating': 2490, 'currently': 2491, 'paper': 2492, 'boost': 2493, 'rank': 2494, 'idk': 2495, 'case': 2496, 'determination': 2497, 'sit': 2498, 'unhealthy': 2499, 'either': 2500, 'blindsided': 2501, 'regular': 2502, 'everyday': 2503, 'xyz': 2504, 'student': 2505, 'finallythis': 2506, 'tip': 2507, 'companyrecruiters': 2508, 'relevant': 2509, 'forwarding': 2510, 'incredibly': 2511, 'powerful': 2512, 'present': 2513, 'greenwich': 2514, 'pickings': 2515, 'scheduling': 2516, 'title': 2517, 'ailment': 2518, 'biased': 2519, 'visits': 2520, 'commitments': 2521, 'alliances': 2522, 'disagreements': 2523, 'rulings': 2524, 'warned': 2525, 'preserved': 2526, 'fundamentally': 2527, 'speak': 2528, 'pretends': 2529, 'govern': 2530, 'breakage': 2531, 'verify': 2532, 'journalist': 2533, 'argue': 2534, 'letter': 2535, 'print': 2536, 'impute': 2537, 'seize': 2538, 'seizure': 2539, 'παρακτω': 2540, 'οποους': 2541, 'καλεται': 2542, 'διαβσει': 2543, 'αποδεχτε': 2544, 'παροχ': 2545, 'επιτρπεται': 2546, 'ενλικους': 2547, 'νω': 2548, 'κμεραςομιλας': 2549, 'προαιρετικ': 2550, 'ενεργοποηση': 2551, 'συντονιστς': 2552, 'βλπουν': 2553, 'κλση': 2554, 'ενεργοποιηθε': 2555, 'φωτογραφιναρχεων': 2556, 'θγουν': 2557, 'αντρρησης': 2558, 'προβλλει': 2559, 'οποτεδποτε': 2560, 'συγκεκριμνη': 2561, 'ενργεια': 2562, 'διρθωση': 2563, 'χρησιμοποηση': 2564, 'δσμευση': 2565, 'διαββαση': 2566, 'προθεσμα': 2567, 'δεκαπντε': 2568, 'ημερν': 2569, 'ενημερσει': 2570, 'ενργειες': 2571, 'προβη': 2572, 'ενδεχομνως': 2573, 'ικανοποησε': 2574, 'απντηση': 2575, 'απρριψης': 2576, 'κοινοποιεται': 2577, 'ενλικες': 2578, 'πνω': 2579, 'δικαιοπρακτικ': 2580, 'ικαντητα': 2581, 'πηγ': 2582, 'αστερευτων': 2583, 'πληροφοριν': 2584, 'τσι': 2585, 'συναντσουν': 2586, 'ακατλληλο': 2587, 'φροντζουν': 2588, 'παιδι': 2589, 'αποκτον': 2590, 'ανλογη': 2591, 'καθοδγηση': 2592, 'επβλεψη': 2593, 'γιατ': 2594, 'αναφρθηκε': 2595, 'δυνατ': 2596, 'διακινονται': 2597, 'ηλικες': 2598, 'παρλα': 2599, 'ανλικοι': 2600, 'επισκτεςχρστες': 2601, 'δηλσουν': 2602, 'εγγραφον': 2603, 'επισκεφτον': 2604, 'ιστοσελδας': 2605, 'δλωσε': 2606, 'απναντι': 2607, 'προκληθε': 2608, 'θση': 2609, 'κυκλοφορα': 2610, 'πορνογραφικν': 2611, 'πρσθεση': 2612, 'περιεχομνουπορνογραφικν': 2613, 'λογαριασμς': 2614, 'διαγραφε': 2615, 'persequor': 2616, 'flat': 2617, 'ian': 2618, 'bradley': 2619, 'hiring': 2620, 'special': 2621, 'startup': 2622, 'yours': 2623, 'difficultimpossible': 2624, 'longterm': 2625, 'annual': 2626, 'unrealistic': 2627, 'empty': 2628, 'sense': 2629, 'tying': 2630, 'stable': 2631, 'example': 2632, 'bam': 2633, 'totally': 2634, 'internaltool': 2635, 'truth': 2636, 'fullfilling': 2637, 'crud': 2638, 'backend': 2639, 'appointment': 2640, 'requirement': 2641, 'exception': 2642, 'wont': 2643, 'growth': 2644, 'umalways': 2645, 'leagues': 2646, 'optimization': 2647, 'billion': 2648, 'debating': 2649, 'launch': 2650, 'hands': 2651, 'deck': 2652, 'sharing': 2653, 'notice': 2654, 'detail': 2655, 'json': 2656, 'match': 2657, 'baby': 2658, 'blurt': 2659, 'joining': 2660, 'local': 2661, 'apps': 2662, 'ecommerce': 2663, 'smallmedium': 2664, 'map': 2665, 'fraction': 2666, 'served': 2667, 'step': 2668, 'larger': 2669, 'deliverables': 2670, 'delivering': 2671, 'nice': 2672, 'glass': 2673, 'whiskey': 2674, 'chill': 2675, 'nightin': 2676, 'costing': 2677, 'easily': 2678, 'causing': 2679, 'realized': 2680, 'competition': 2681, 'swesdecomputer': 2682, 'hadnt': 2683, 'four': 2684, 'nonstop': 2685, 'overtime': 2686, 'spending': 2687, 'mother': 2688, 'shes': 2689, 'anytime': 2690, 'weve': 2691, 'wheelchaired': 2692, 'unplanned': 2693, 'uncertain': 2694, 'trust': 2695, 'patience': 2696, 'proper': 2697, 'healthy': 2698, 'increased': 2699, 'velocityquantity': 2700, 'decrease': 2701, 'fifty': 2702, 'agree': 2703, 'major': 2704, 'confusion': 2705, 'paradox': 2706, 'grow': 2707, 'lack': 2708, 'imagination': 2709, 'debatable': 2710, 'theyll': 2711, 'avenue': 2712, 'towards': 2713, 'somehow': 2714, 'astrophysics': 2715, 'nanophotonics': 2716, 'modest': 2717, 'lots': 2718, 'themselves': 2719, 'decent': 2720, 'programmingstats': 2721, 'fall': 2722, 'assistant': 2723, 'statistician': 2724, 'location': 2725, 'ideal': 2726, 'mvc': 2727, 'ltcd': 2728, 'edge': 2729, 'jobbills': 2730, 'crazy': 2731, 'dry': 2732, 'deserve': 2733, 'workplace': 2734, 'prompt': 2735, 'blowupteardown': 2736, 'correct': 2737, 'utter': 2738, 'gervais': 2739, 'future': 2740, 'apis': 2741, 'candy': 2742, 'editor': 2743, 'clientfacing': 2744, 'techjust': 2745, 'ignore': 2746, 'careerit': 2747, 'tailor': 2748, 'generic': 2749, 'honor': 2750, 'customer': 2751, 'precisely': 2752, 'master': 2753, 'center': 2754, 'tire': 2755, 'deteriorate': 2756, 'loanblend': 2757, 'perceptibly': 2758, 'χρονολογικ': 2759, 'ηλικα': 2760, 'ετνδιαγρφεται': 2761, 'εγγραφε': 2762, 'αληθες': 2763, 'ακριβες': 2764, 'γκυρες': 2765, 'πλρεις': 2766, 'ζητονται': 2767, 'αιτσεις': 2768, 'ενημερνει': 2769, 'διατηρονται': 2770, 'αληθ': 2771, 'ακριβ': 2772, 'γκυρα': 2773, 'ενημερωμνα': 2774, 'παραχραξη': 2775, 'αλλοωση': 2776, 'αναγνωριστικν': 2777, 'παραπλνηση': 2778, 'προλευση': 2779, 'μεταδδεται': 2780, 'ε': 2781, 'τομο': 2782, 'εμπιστευτικς': 2783, 'σχσης': 2784, 'στ': 2785, 'λογισμικο': 2786, 'κειμνου': 2787, 'εικνας': 2788, 'χου': 2789, 'animation': 2790, 'τρτου': 2791, 'ζ': 2792, 'αυτκλητης': 2793, 'εξουσιοδοτημνης': 2794, 'διαφμισης': 2795, 'λλου': 2796, 'προντων': 2797, 'ανεπιθμητων': 2798, 'προσκαλομενων': 2799, 'λπτη': 2800, 'ηλεκτρονικν': 2801, 'ανεπιθμητης': 2802, 'παρενχληση': 2803, 'ιδιωτικς': 2804, 'ζως': 2805, 'ατομικν': 2806, 'κοινωνικν': 2807, 'δικαιωμτων': 2808, 'κνει': 2809, 'προκαταρκτικ': 2810, 'λεγχο': 2811, 'αποκλειστικς': 2812, 'ρνησης': 2813, 'ανρτησης': 2814, 'δημοσευσης': 2815, 'μετακνησης': 2816, 'διαγραφς': 2817, 'διατθεται': 2818, 'απαγορεουν': 2819, 'ακολουθον': 2820, 'αναφερμενων': 2821, 'εξαιρσεων': 2822, 'γραφικν': 2823, 'φωτογραφιν': 2824, 'σχεδων': 2825, 'κειμνων': 2826, 'παρεχμενων': 2827, 'γενικ': 2828, 'κατατεθειμνα': 2829, 'προστατεονται': 2830, 'ελληνικο': 2831, 'διεθνν': 2832, 'συμβσεων': 2833, 'συνθηκν': 2834, 'λω': 2835, 'μρει': 2836, 'πλησης': 2837, 'αντιγραφς': 2838, 'τροποποησης': 2839, 'αναπαραγωγς': 2840, 'αναδημοσευσης': 2841, 'φορτωθε': 2842, 'μεταδοθε': 2843, 'διανεμηθε': 2844, 'εξαιρεται': 2845, 'μεμονωμνης': 2846, 'αποθκευσης': 2847, 'ενς': 2848, 'μνου': 2849, 'αντιγρφου': 2850, 'απλ': 2851, 'ηλεκτρονικ': 2852, 'απαλοιφ': 2853, 'νδειξης': 2854, 'προλευσς': 2855, 'θγονται': 2856, 'βιομηχανικς': 2857, 'αναφρονται': 2858, 'ηλεκτρονικς': 2859, 'κμβου': 2860, 'αντστοιχων': 2861, 'οργανισμν': 2862, 'εταιρειν': 2863, 'ενσεων': 2864, 'εκδσεων': 2865, 'βιομηχανικ': 2866, 'φορες': 2867, 'παρχεται': 2868, 'αναπαργει': 2869, 'αντιγρφει': 2870, 'πωλε': 2871, 'μεταπωλε': 2872, 'εκμεταλλεεται': 2873, 'κωδικο': 2874, 'πρσβασης': 2875, 'πιστεει': 2876, 'παραβισει': 2877, 'γρμμα': 2878, 'πνεμα': 2879, 'παρντων': 2880, 'successful': 2881, 'corporate': 2882, 'slack': 2883, 'channel': 2884, 'attend': 2885, 'teambuilding': 2886, 'exactly': 2887, 'wikipedia': 2888, 'compress': 2889, 'mongo': 2890, 'collection': 2891, 'save': 2892, 'kyear': 2893, 'impactful': 2894, 'essentially': 2895, 'seriously': 2896, 'retro': 2897, 'drain': 2898, 'radar': 2899, 'fathom': 2900, 'book': 2901, 'undergraduate': 2902, 'solid': 2903, 'foundation': 2904, 'breadth': 2905, 'fully': 2906, 'sell': 2907, 'grinding': 2908, 'baiting': 2909, 'therapist': 2910, 'subreddit': 2911, 'terminated': 2912, 'visibly': 2913, 'teary': 2914, 'toxic': 2915, 'noise': 2916, 'sometimes': 2917, 'wish': 2918, 'factor': 2919, 'buying': 2920, 'stipend': 2921, 'qualify': 2922, 'halfway': 2923, 'sciences': 2924, 'wife': 2925, 'machine': 2926, 'type': 2927, 'shittier': 2928, 'toolsframeworks': 2929, 'titles': 2930, 'itll': 2931, 'private': 2932, 'irl': 2933, 'indemand': 2934, 'majority': 2935, 'analysis': 2936, 'wellknown': 2937, 'hasnt': 2938, 'bother': 2939, 'tracker': 2940, 'consider': 2941, 'certifications': 2942, 'route': 2943, 'required': 2944, 'wants': 2945, 'wow': 2946, 'shat': 2947, 'grind': 2948, 'nerds': 2949, 'computers': 2950, 'lengths': 2951, 'hunting': 2952, 'swe': 2953, 'aside': 2954, 'eligible': 2955, 'timely': 2956, 'couple': 2957, 'dictate': 2958, 'cactus': 2959, 'willing': 2960, 'ship': 2961, 'sociopath': 2962, 'variability': 2963, 'mediocre': 2964, 'outright': 2965, 'dishonest': 2966, 'unjustifiably': 2967, 'managerial': 2968, 'meritocracy': 2969, 'ladder': 2970, 'theyd': 2971, 'fine': 2972, 'hopefully': 2973, 'starter': 2974, 'manger': 2975, 'sitting': 2976, 'netqa': 2977, 'sharpen': 2978, 'messaging': 2979, 'connect': 2980, 'spread': 2981, 'thin': 2982, 'blend': 2983, 'solutionswhat': 2984, 'presales': 2985, 'hear': 2986, 'parent': 2987, 'articulation': 2988, 'class': 2989, 'profoundly': 2990, 'europium': 2991, 'αποδχονται': 2992, 'παρλο': 2993, 'απαρατητη': 2994, 'τεχνολογικ': 2995, 'υποδομ': 2996, 'κεμενα': 2997, 'φωτογραφεςεικνες': 2998, 'μηνματα': 2999, 'κα': 3000, 'προσθτουν': 3001, 'μεταφρεται': 3002, 'ιδιωτικ': 3003, 'παραμνει': 3004, 'προσθτει': 3005, 'σημανει': 3006, 'αποστλλει': 3007, 'καθιστ': 3008, 'δυνατν': 3009, 'σνολ': 3010, 'οπτε': 3011, 'ακρβεια': 3012, 'ακεραιτητα': 3013, 'νομιμτητα': 3014, 'ποιτητα': 3015, 'ττοιου': 3016, 'χρησιμοποιντας': 3017, 'εκτεθε': 3018, 'ανθικο': 3019, 'παρνομο': 3020, 'παραλεψεις': 3021, 'βλβη': 3022, 'προκψουν': 3023, 'καθσταται': 3024, 'ειδοποιηθε': 3025, 'αθμιτου': 3026, 'ταυτχρονα': 3027, 'λειτουργα': 3028, 'οποος': 3029, 'βιντεοσκπηση': 3030, 'ηχογρφηση': 3031, 'απαγορεονται': 3032, 'αυστηρς': 3033, 'ενδεικτικ': 3034, 'περιοριστικ': 3035, 'χρησιμοποιον': 3036, 'επιβλαβος': 3037, 'απειλητικο': 3038, 'επιζμιου': 3039, 'δυσφημιστικο': 3040, 'χυδαου': 3041, 'βαιου': 3042, 'υβριστικο': 3043, 'ρατσιστικο': 3044, 'αποδοκιμαστου': 3045, 'προσωπικτητα': 3046, 'προκαλε': 3047, 'συναισθματα': 3048, 'μσους': 3049, 'τρμου': 3050, 'συνιστμενο': 3051, 'μμηση': 3052, 'νομικο': 3053, 'φυσικο': 3054, 'ταυττητα': 3055, 'παραπλανητικ': 3056, 'αναφορικ': 3057, 'σχση': 3058, 'συνεργασα': 3059, 'κποιο': 3060, 'φυσικ': 3061, 'πρσωπο': 3062, 'τροποποιε': 3063, 'διακπτει': 3064, 'μνιμα': 3065, 'διαχεριση': 3066, 'υπκειται': 3067, 'ελληνικς': 3068, 'νομοθεσας': 3069, 'συμπληρωθε': 3070, 'αποφσεις': 3071, 'προδρου': 3072, 'επιτροπς': 3073, 'π': 3074, 'οδηγες': 3075, 'ροι': 3076, 'διατυπνονται': 3077, 'λαμβανομνων': 3078, 'υπψη': 3079, 'τσο': 3080, 'ραγδαας': 3081, 'ανπτυξης': 3082, 'τεχνολογας': 3083, 'σο': 3084, 'υπρχοντος': 3085, 'ανεπτυγμνου': 3086, 'πλγματος': 3087, 'νομικν': 3088, 'ρυθμσεων': 3089, 'ζητματα': 3090, 'ενδεχμενη': 3091, 'ρθμιση': 3092, 'διατηρομε': 3093, 'αλλαγς': 3094, 'ενημρωσης': 3095, 'υπρχον': 3096, 'ενδεχμενο': 3097, 'παρν': 3098, 'gergian': 3099, 'retention': 3100, 'questions': 3101, 'vague': 3102, 'fuzzy': 3103, 'behind': 3104, 'complaining': 3105, 'hate': 3106, 'wlb': 3107, 'yoe': 3108, 'bonus': 3109, 'lease': 3110, 'worse': 3111, 'kick': 3112, 'catch': 3113, 'sleep': 3114, 'relief': 3115, 'joy': 3116, 'constantly': 3117, 'ahhh': 3118, 'leetcodebfsdfsstring': 3119, 'traversal': 3120, 'exercise': 3121, 'cookingbaking': 3122, 'alright': 3123, 'proverbial': 3124, 'pie': 3125, 'scenario': 3126, 'pre': 3127, 'hypothetically': 3128, 'augment': 3129, 'networks': 3130, 'tools': 3131, 'categories': 3132, 'maturity': 3133, 'innovation': 3134, 'twice': 3135, 'upper': 3136, 'often': 3137, 'crying': 3138, 'becoming': 3139, 'reeled': 3140, 'anybody': 3141, 'actively': 3142, 'hostile': 3143, 'profession': 3144, 'universities': 3145, 'sysadmindeveloper': 3146, 'archives': 3147, 'digital': 3148, 'computational': 3149, 'bio': 3150, 'bioinfo': 3151, 'par': 3152, 'helped': 3153, 'ripped': 3154, 'awful': 3155, 'competent': 3156, 'fit': 3157, 'personality': 3158, 'nowand': 3159, 'shift': 3160, 'suddenly': 3161, 'interviewsalmost': 3162, 'solutionsrelated': 3163, 'final': 3164, 'round': 3165, 'cyber': 3166, 'takehome': 3167, 'pivot': 3168, 'door': 3169, 'scarce': 3170, 'bootcamp': 3171, 'drastically': 3172, 'count': 3173, 'devising': 3174, 'complain': 3175, 'loom': 3176, 'deadline': 3177, 'electronic': 3178, 'tilt': 3179, 'release': 3180, 'decidedly': 3181, 'snap': 3182, 'plant': 3183, 'acerate': 3184, 'leaf': 3185, 'balls': 3186, 'server': 3187, 'encountering': 3188, 'bullshit': 3189, 'fakeness': 3190, 'primary': 3191, 'horizon': 3192, 'tens': 3193, 'dollars': 3194, 'counting': 3195, 'maxed': 3196, 'macbook': 3197, 'ever': 3198, 'promotion': 3199, 'transformative': 3200, 'tbh': 3201, 'hack': 3202, 'aggressive': 3203, 'blind': 3204, 'migration': 3205, 'bare': 3206, 'vp': 3207, 'portfolio': 3208, 'event': 3209, 'ultimately': 3210, 'anticlimactic': 3211, 'avoid': 3212, 'doxxing': 3213, 'digitally': 3214, 'manually': 3215, 'file': 3216, 'paperwork': 3217, 'compliant': 3218, 'prone': 3219, 'versus': 3220, 'automatically': 3221, 'persisted': 3222, 'delays': 3223, 'tried': 3224, 'ut': 3225, 'lateral': 3226, 'austin': 3227, 'campus': 3228, 'input': 3229, 'academia': 3230, 'college': 3231, 'dox': 3232, 'surprising': 3233, 'heck': 3234, 'priority': 3235, 'bandwidth': 3236, 'gains': 3237, 'indians': 3238, 'oh': 3239, 'whatever': 3240, 'hybrid': 3241, 'hey': 3242, 'singular': 3243, 'minimum': 3244, 'inperson': 3245, 'statelevel': 3246, 'stupid': 3247, 'completely': 3248, 'shattered': 3249, 'somewhat': 3250, 'introverted': 3251, 'tasks': 3252, 'module': 3253, 'questioning': 3254, 'valid': 3255, 'typo': 3256, 'camps': 3257, 'dreaming': 3258, 'deploying': 3259, 'handing': 3260, 'considering': 3261, 'changed': 3262, 'hazard': 3263, 'push': 3264, 'transportation': 3265, 'purportedly': 3266, 'scope': 3267, 'grade': 3268, 'dependant': 3269, 'candidate': 3270, 'exploit': 3271, 'employees': 3272, 'docs': 3273, 'researching': 3274, 'firms': 3275, 'cutting': 3276, 'spooking': 3277, 'execs': 3278, 'golden': 3279, 'buy': 3280, 'built': 3281, 'depressing': 3282, 'seeing': 3283, 'complaints': 3284, 'prospects': 3285, 'ass': 3286, 'place': 3287, 'june': 3288, 'contracttohire': 3289, 'itbut': 3290, 'thanks': 3291, 'budget': 3292, 'widest': 3293, 'leaned': 3294, 'searching': 3295, 'shine': 3296, 'referred': 3297, 'habit': 3298, 'excite': 3299, 'narrative': 3300, 'study': 3301, 'forte': 3302, 'populate': 3303, 'sound': 3304, 'premise': 3305, 'involve': 3306, 'friend': 3307, 'temper': 3308, 'land': 3309, 'accidentally': 3310, 'charged': 3311, 'fees': 3312, 'blinked': 3313, 'unlocking': 3314, 'known': 3315, 'sort': 3316, 'poured': 3317, 'preparing': 3318, 'quit': 3319, 'uses': 3320, 'sucked': 3321, 'create': 3322, 'removes': 3323, 'automated': 3324, 'points': 3325, 'partner': 3326, 'benefited': 3327, 'marketing': 3328, 'earn': 3329, 'posts': 3330, 'ran': 3331, 'listing': 3332, 'unpredictable': 3333, 'offshore': 3334, 'overqualified': 3335, 'goes': 3336, 'salaries': 3337, 'gone': 3338, 'hoping': 3339, 'jr': 3340, 'abuse': 3341, 'thirdly': 3342, 'literal': 3343, 'interns': 3344, 'developing': 3345, 'leans': 3346, 'excited': 3347, 'requires': 3348, 'picked': 3349, 'perfect': 3350, 'learned': 3351, 'recruiters': 3352, 'shoes': 3353, 'strategy': 3354, 'choosing': 3355, 'underrated': 3356, 'strengths': 3357, 'savant': 3358, 'refresh': 3359, 'bursts': 3360, 'opposed': 3361, 'casting': 3362, 'gained': 3363, 'helpdesk': 3364, 'environment': 3365, 'ballad': 3366, 'physique': 3367, 'hanker': 3368, 'debate': 3369, 'plan': 3370, 'attest': 3371, 'academician': 3372, 'inflate': 3373, 'ego': 3374, 'lacrimation': 3375, 'insufficiency': 3376, 'pushing': 3377, 'users': 3378, 'linked': 3379, 'lists': 3380, 'blew': 3381, 'tiny': 3382, 'saving': 3383, 'pages': 3384, 'paraphrased': 3385, 'talking': 3386, 'programmers': 3387, 'sites': 3388, 'horrible': 3389, 'dive': 3390, 'deeper': 3391, 'speciality': 3392, 'covered': 3393, 'studies': 3394, 'concentrate': 3395, 'relieved': 3396, 'sprint': 3397, 'caused': 3398, 'fixed': 3399, 'keys': 3400, 'knew': 3401, 'boss': 3402, 'organize': 3403, 'produces': 3404, 'eventually': 3405, 'hb': 3406, 'min': 3407, 'source': 3408, 'twitter': 3409, 'clone': 3410, 'practicing': 3411, 'gpa': 3412, 'counterstrike': 3413, 'surprised': 3414, 'persons': 3415, 'shitty': 3416, 'sooner': 3417, 'luck': 3418, 'wrapped': 3419, 'loved': 3420, 'cuts': 3421, 'brought': 3422, 'kept': 3423, 'campaigner': 3424, 'drilling': 3425, 'stereotype': 3426, 'dislike': 3427, 'eye': 3428, 'neglect': 3429, 'nightmare': 3430, 'boundlessly': 3431, 'catmint': 3432, 'compare': 3433, 'biotechnology': 3434, 'lend': 3435, 'referral': 3436, 'cipher': 3437, 'soviet': 3438, 'presentment': 3439, 'buffet': 3440, 'attract': 3441, 'microphone': 3442, 'improbable': 3443, 'h': 3444, 'provider': 3445, 'website': 3446, 'kinds': 3447, 'theatre': 3448, 'wanting': 3449, 'convince': 3450, 'lifes': 3451, 'icebreakers': 3452, 'preventing': 3453, 'slower': 3454, 'error': 3455, 'stuck': 3456, 'crossroad': 3457, 'impacted': 3458, 'livelihood': 3459, 'la': 3460, 'pto': 3461, 'deteriorating': 3462, 'despite': 3463, 'pms': 3464, 'calls': 3465, 'restrictions': 3466, 'breaks': 3467, 'stricter': 3468, 'axe': 3469, 'fell': 3470, 'suits': 3471, 'lived': 3472, 'thousands': 3473, 'dread': 3474, 'appreciated': 3475, 'laid': 3476, 'lean': 3477, 'extrapolate': 3478, 'cheaper': 3479, 'profitability': 3480, 'shoring': 3481, 'hm': 3482, 'runs': 3483, 'domain': 3484, 'frankly': 3485, 'helps': 3486, 'specialty': 3487, 'responses': 3488, 'interning': 3489, 'embedded': 3490, 'suck': 3491, 'finishing': 3492, 'brutal': 3493, 'music': 3494, 'maritime': 3495, 'fool': 3496, 'optimum': 3497, 'clang': 3498, 'wonder': 3499, 'regretful': 3500, 'ma': 3501, 'simple': 3502, 'avocation': 3503, 'impregnation': 3504, 'refer': 3505, 'bluffly': 3506, 'calculation': 3507, 'reasonably': 3508, 'depress': 3509, 'ad': 3510, 'burn': 3511, 'asserted': 3512, 'courts': 3513, 'battle': 3514, 'countermeasure': 3515, 'liquor': 3516, 'pledge': 3517, 'lift': 3518, 'distract': 3519, 'margin': 3520, 'mathematics': 3521, 'powered': 3522, 'limited': 3523, 'nowadays': 3524, 'interviewers': 3525, 'treating': 3526, 'normal': 3527, 'results': 3528, 'retaining': 3529, 'motivated': 3530, 'ie': 3531, 'booking': 3532, 'leads': 3533, 'dude': 3534, 'describing': 3535, 'candidates': 3536, 'genuinely': 3537, 'spent': 3538, 'achievement': 3539, 'dropping': 3540, 'unused': 3541, 'ensure': 3542, 'individual': 3543, 'online': 3544, 'crash': 3545, 'reveal': 3546, 'called': 3547, 'deteriorated': 3548, 'travelling': 3549, 'regret': 3550, 'leaving': 3551, 'expectations': 3552, 'learnt': 3553, 'stacks': 3554, 'rest': 3555, 'constrained': 3556, 'directors': 3557, 'executives': 3558, 'glitch': 3559, 'witch': 3560, 'band': 3561, 'realize': 3562, 'lifting': 3563, 'institutes': 3564, 'overlapping': 3565, 'explore': 3566, 'listings': 3567, 'enjoyed': 3568, 'alumni': 3569, 'referrals': 3570, 'references': 3571, 'terrible': 3572, 'tier': 3573, 'failures': 3574, 'promoting': 3575, 'twiddling': 3576, 'thumbs': 3577, 'hes': 3578, 'hydrogen': 3579, 'supplier': 3580, 'light': 3581, 'contempt': 3582, 'premenstrual': 3583, 'syndrome': 3584, 'restriction': 3585, 'rigorous': 3586, 'ax': 3587, 'hide': 3588, 'suit': 3589, 'modification': 3590, 'consumer': 3591, 'incarnate': 3592, 'weigh': 3593, 'misprint': 3594, 'movable': 3595, 'detect': 3596, 'initiation': 3597, 'proceeding': 3598, 'insist': 3599, 'paramedic': 3600, 'district': 3601, 'intent': 3602, 'perspective': 3603, 'hardest': 3604, 'recruiting': 3605, 'bs': 3606, 'facts': 3607, 'claims': 3608, 'answering': 3609, 'jerking': 3610, 'lights': 3611, 'exciting': 3612, 'metal': 3613, 'o': 3614, 'tabs': 3615, 'figured': 3616, 'coordinating': 3617, 'flipped': 3618, 'decided': 3619, 'ti': 3620, 'allowed': 3621, 'ridiculous': 3622, 'wonders': 3623, 'outputting': 3624, 'understands': 3625, 'sized': 3626, 'existence': 3627, 'far': 3628, 'driving': 3629, 'contribute': 3630, 'updates': 3631, 'stake': 3632, 'employed': 3633, 'conclusion': 3634, 'embodies': 3635, 'stated': 3636, 'weighs': 3637, 'starting': 3638, 'pays': 3639, 'sets': 3640, 'paths': 3641, 'treat': 3642, 'convention': 3643, 'motivate': 3644, 'explorer': 3645, 'engagement': 3646, 'fellow': 3647, 'pathetic': 3648, 'sorrow': 3649, 'expectation': 3650, 'remainder': 3651, 'deficit': 3652, 'disorder': 3653, 'hectometer': 3654, 'imbrication': 3655, 'moon': 3656, 'recently': 3657, 'scheme': 3658, 'underestimate': 3659, 'strength': 3660, 'initiate': 3661, 'explosion': 3662, 'oppose': 3663, 'invited': 3664, 'ruling': 3665, 'appraisal': 3666, 'probe': 3667, 'extinguish': 3668, 'muslim': 3669, 'militant': 3670, 'repeat': 3671, 'style': 3672, 'older': 3673, 'situations': 3674, 'raises': 3675, 'frugal': 3676, 'recommended': 3677, 'pro': 3678, 'classes': 3679, 'curriculum': 3680, 'exposed': 3681, 'languages': 3682, 'kinda': 3683, 'catnip': 3684, 'consumers': 3685, 'limiting': 3686, 'worlds': 3687, 'saturation': 3688, 'concerning': 3689, 'live': 3690, 'careers': 3691, 'bluntly': 3692, 'figuring': 3693, 'fairly': 3694, 'advertising': 3695, 'burnt': 3696, 'aged': 3697, 'enroll': 3698, 'economical': 3699, 'recommend': 3700, 'drop': 3701, 'guarantee': 3702, 'dash': 3703, 'cause': 3704, 'repair': 3705, 'counterattack': 3706, 'promote': 3707, 'twirl': 3708, 'thumb': 3709, 'radiance': 3710, 'derive': 3711, 'desk': 3712, 'boring': 3713, 'stereotypes': 3714, 'presents': 3715, 'interesting': 3716, 'offers': 3717, 'stories': 3718, 'program': 3719, 'certified': 3720, 'effort': 3721, 'fooling': 3722, 'juniors': 3723, 'anyways': 3724, 'effecting': 3725, 'neglecting': 3726, 'nightmares': 3727, 'dying': 3728, 'worried': 3729, 'sucks': 3730, 'mood': 3731, 'lastly': 3732, 'matters': 3733, 'overhauled': 3734, 'transferable': 3735, 'noticed': 3736, 'theater': 3737, 'convert': 3738, 'icebreaker': 3739, 'buttocks': 3740, 'user': 3741, 'blow': 3742, 'bantam': 3743, 'spot': 3744, 'paraphrase': 3745, 'metallic': 3746, 'element': 3747, 'oxygen': 3748, 'check': 3749, 'calculate': 3750, 'flip': 3751, 'decide': 3752, 'titanium': 3753, 'propose': 3754, 'bargain': 3755, 'construct': 3756, 'enchantress': 3757, 'average': 3758, 'implant': 3759, 'oklahoman': 3760, 'maltreatment': 3761, 'fortune': 3762, 'third': 3763, 'environments': 3764, 'tie': 3765, 'interviewing': 3766, 'benefits': 3767, 'broken': 3768, 'disliked': 3769, 'eyed': 3770, 'sorry': 3771, 'mom': 3772, 'recharging': 3773, 'simpler': 3774, 'hobbies': 3775, 'academic': 3776, 'feat': 3777, 'charge': 3778, 'fee': 3779, 'blink': 3780, 'accomplishment': 3781, 'page': 3782, 'unlock': 3783, 'pour': 3784, 'fix': 3785, 'intersection': 3786, 'lodge': 3787, 'lanthanum': 3788, 'takeoff': 3789, 'honkytonk': 3790, 'deep': 3791, 'survey': 3792, 'dressed': 3793, 'ore': 3794, 'uncover': 3795, 'gain': 3796, 'restrain': 3797, 'firm': 3798, 'film': 3799, 'editing': 3800, 'spook': 3801, 'aureate': 3802, 'generalize': 3803, 'profitableness': 3804, 'hemoglobin': 3805, 'minute': 3806, 'beginning': 3807, 'chirrup': 3808, 'ringer': 3809, 'careless': 3810, 'icky': 3811, 'coating': 3812, 'barbarous': 3813, 'recruiter': 3814, 'optimal': 3815, 'develops': 3816, 'looming': 3817, 'deadlines': 3818, 'emails': 3819, 'middle': 3820, 'hired': 3821, 'deeply': 3822, 'driven': 3823, 'researchers': 3824, 'whos': 3825, 'internships': 3826, 'managers': 3827, 'inflated': 3828, 'egos': 3829, 'relish': 3830, 'tearing': 3831, 'inadequacy': 3832, 'gets': 3833, 'prevent': 3834, 'remove': 3835, 'automatize': 3836, 'spouse': 3837, 'appreciate': 3838, 'shore': 3839, 'visual': 3840, 'perception': 3841, 'swot': 3842, 'perfective': 3843, 'dependent': 3844, 'manage': 3845, 'includes': 3846, 'clicking': 3847, 'works': 3848, 'moved': 3849, 'needle': 3850, 'serve': 3851, 'deliverable': 3852, 'prevail': 3853, 'delay': 3854, 'tool': 3855, 'adulthood': 3856, 'invention': 3857, 'fuss': 3858, 'rend': 3859, 'chip': 3860, 'stagger': 3861, 'belly': 3862, 'laugh': 3863, 'denounce': 3864, 'length': 3865, 'hunt': 3866, 'shatter': 3867, 'invaginate': 3868, 'faculty': 3869, 'reappraisal': 3870, 'wrap': 3871}\n"
          ]
        }
      ]
    }
  ]
}